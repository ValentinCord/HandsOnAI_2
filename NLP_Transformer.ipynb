{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkYSO760PA22uJiZCbkS8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "ndfJjNRbOtqA",
        "outputId": "ddbe06d6-f51a-4494-ff91-28fd3e9f677b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 12 14:31:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    27W /  70W |  15102MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "MZ_nxGkkO7BB",
        "outputId": "a495305e-adcc-400f-f032-349bf33406f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basics \n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transformers \n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# plot \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# torch \n",
        "import torch\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# nltk \n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "IItKtGo1O8yQ",
        "outputId": "11c62fe8-c570-4f02-a41a-5803f4ac9867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGXyKBKhQAVX",
        "outputId": "9154277e-506e-4eec-fed8-1e67c81a7be7"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture et analyse pandas"
      ],
      "metadata": {
        "id": "quksqXzGSHdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 10\n",
        "VALID_BATCH_SIZE = 10\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "LEN_TEXT = 300\n",
        "OVERLAP = 50"
      ],
      "metadata": {
        "id": "h__VY3DBvT6V"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_train.csv'\n",
        "test_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_test.csv'\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# suppression des colonnes inutiles \n",
        "df = df.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "df_test = df_test.drop(['Unnamed: 0', 'target_name'], axis = 1)"
      ],
      "metadata": {
        "id": "tiOqzZa_QBHP"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('french'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    #text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    #text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "metadata": {
        "id": "jb8g1SRXMV6Y"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data'] = df['data'].apply(clean_text)\n",
        "df_test['data'] = df_test['data'].apply(clean_text)"
      ],
      "metadata": {
        "id": "MFuS0cn_NznG"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fpbc0ayFONt5",
        "outputId": "f6b5b064-48d1-4037-e865-027bfc7dab9e"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data  label\n",
              "0  22e jour consécutif grève reconductible contre...      0\n",
              "1  depuis plusieurs mois, initiatives chercheurs ...      0\n",
              "2  google vient d'introduire mise jour applicatio...      0\n",
              "3  portrait. chacun s’empresse autour d’elle tand...      0\n",
              "4  « n’y a risque pénurie » carburant, a déclaré ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-031e2dd6-be30-41ee-822c-3e6b26adf710\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22e jour consécutif grève reconductible contre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>depuis plusieurs mois, initiatives chercheurs ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>google vient d'introduire mise jour applicatio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>portrait. chacun s’empresse autour d’elle tand...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>« n’y a risque pénurie » carburant, a déclaré ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-031e2dd6-be30-41ee-822c-3e6b26adf710')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-031e2dd6-be30-41ee-822c-3e6b26adf710 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-031e2dd6-be30-41ee-822c-3e6b26adf710');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//(LEN_TEXT - OVERLAP) >0:\n",
        "        n = len(text1.split())//(LEN_TEXT - OVERLAP)\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*(LEN_TEXT - OVERLAP):w*(LEN_TEXT - OVERLAP) + LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total"
      ],
      "metadata": {
        "id": "CsSspiWDNQ89"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_split'] = df['data'].apply(get_split)\n",
        "df['len_split'] = df['text_split'].apply(lambda x: len(x))\n",
        "\n",
        "df_test['text_split'] = df_test['data'].apply(get_split)\n",
        "df_test['len_split'] = df_test['text_split'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "zPkVbv9gNSh-"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['len_split'].value_counts()"
      ],
      "metadata": {
        "id": "BFaerOjcezKm",
        "outputId": "1d5e18b4-2f1a-4cb3-96ac-b89a03beaa1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     1245\n",
              "2      129\n",
              "3       45\n",
              "4       24\n",
              "7        5\n",
              "6        5\n",
              "5        2\n",
              "12       1\n",
              "8        1\n",
              "14       1\n",
              "Name: len_split, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['len_split'].value_counts()"
      ],
      "metadata": {
        "id": "WdJw9CkOfZHP",
        "outputId": "1cfcd749-861a-4729-aec3-0b06955dedd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     419\n",
              "2      42\n",
              "3      11\n",
              "5       6\n",
              "4       5\n",
              "7       1\n",
              "6       1\n",
              "11      1\n",
              "Name: len_split, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verification du fonctionnement\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if len(row['text_split']) > 1: \n",
        "    print(index)\n",
        "    break\n",
        "\n",
        "print(df['text_split'][31][0].split()[(LEN_TEXT - OVERLAP):])\n",
        "print(df['text_split'][31][1].split()[:OVERLAP])"
      ],
      "metadata": {
        "id": "6UFYbVkZw-5x",
        "outputId": "40c74554-1207-45ba-ee74-e51c7645f594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "['natalia', 'rybczynski', 'paléobiologiste.', 'suivez', 'recherche', 'fossiles', 'étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago,', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour,', 'formation']\n",
            "['natalia', 'rybczynski', 'paléobiologiste.', 'suivez', 'recherche', 'fossiles', 'étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago,', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour,', 'formation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(df): \n",
        "  train_l = []\n",
        "  label_l = []\n",
        "  for idx,row in df.iterrows():\n",
        "      for l in row['text_split']:\n",
        "          train_l.append(l)\n",
        "          label_l.append([1 if row['label'] == i else 0 for i in range(2)])\n",
        "\n",
        "  return pd.DataFrame({'data':train_l, 'label':label_l})"
      ],
      "metadata": {
        "id": "X0tOshbBOtdh"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = create_df(df)\n",
        "cleaned_df_test = create_df(df_test)"
      ],
      "metadata": {
        "id": "c3Ef_wbQO2DV"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len, is_target = True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = dataframe\n",
        "        self.text = dataframe.data\n",
        "        self.max_len = max_len\n",
        "        if is_target: \n",
        "          self.targets = self.df.label\n",
        "        else: \n",
        "          self.targets = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.targets is None: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "          }\n",
        "        else: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "          }"
      ],
      "metadata": {
        "id": "B1zIS8_5f1km"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tranfo_name = \"cmarkea/distilcamembert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tranfo_name)"
      ],
      "metadata": {
        "id": "d19z9CWe2D7W"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "train_dataset=cleaned_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=cleaned_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(cleaned_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(cleaned_df, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(cleaned_df_test, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "unfGKfEHg0Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce8ab19-2b85-4a69-9fcf-d3eb0a776b17"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (1843, 2)\n",
            "TRAIN Dataset: (1474, 2)\n",
            "TEST Dataset: (369, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "FkinDs9Mj42G"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "      super(BERTClass, self).__init__()\n",
        "      self.l1 = CamembertModel.from_pretrained(tranfo_name)\n",
        "      self.l3 = torch.nn.Linear(768, 2) #2 = binary classification\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      output = self.l3(output_1['pooler_output'])\n",
        "\n",
        "      return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "YI-RQetem1Ou",
        "outputId": "7a9f052a-78be-40c5-ba0d-270cd1ade5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l3): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "cHuUpT28bBFy"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        token_type_ids = data['token_type_ids'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%10==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GkLpQpkrcXj0"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "V1oQxlezm-qh",
        "outputId": "c20fd2fe-f4c8-47cc-8277-1bf1cad276d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.7094480991363525\n",
            "Epoch: 0, Loss:  0.46974673867225647\n",
            "Epoch: 0, Loss:  0.5431113243103027\n",
            "Epoch: 0, Loss:  0.4170994758605957\n",
            "Epoch: 0, Loss:  0.3294007480144501\n",
            "Epoch: 0, Loss:  0.20950499176979065\n",
            "Epoch: 0, Loss:  0.11740458011627197\n",
            "Epoch: 0, Loss:  0.19770044088363647\n",
            "Epoch: 0, Loss:  0.28697702288627625\n",
            "Epoch: 0, Loss:  0.11256702989339828\n",
            "Epoch: 0, Loss:  0.2144276648759842\n",
            "Epoch: 0, Loss:  0.06517084687948227\n",
            "Epoch: 0, Loss:  0.19719281792640686\n",
            "Epoch: 0, Loss:  0.11961408704519272\n",
            "Epoch: 0, Loss:  0.05906033515930176\n",
            "Epoch: 0, Loss:  0.05943263694643974\n",
            "Epoch: 0, Loss:  0.19426369667053223\n",
            "Epoch: 0, Loss:  0.10858414322137833\n",
            "Epoch: 0, Loss:  0.32572126388549805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation():\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "      for _, data in enumerate(testing_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "        m = torch.nn.Softmax(dim=1)\n",
        "        fin_outputs.extend(torch.round(m(outputs)).cpu().detach().numpy().tolist())\n",
        "\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "HqGsmQgV7IJ0"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "outputs, targets = validation()\n",
        "accuracy = metrics.accuracy_score(targets, outputs)\n",
        "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "qqjHEDooHz4i",
        "outputId": "6715c806-fc8d-4d99-ba10-0a0d0aa1eb2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.9590163934426229\n",
            "F1 Score (Micro) = 0.9590163934426229\n",
            "F1 Score (Macro) = 0.9554316409046939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test['pred'] = outputs\n",
        "cleaned_df_test.head()"
      ],
      "metadata": {
        "id": "V1A2NZ6deQiu",
        "outputId": "0e511aec-db1d-4169-d581-c1b19ea5cf16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data   label        pred\n",
              "0  président groupe lrem a pris toutes pincettes....  [1, 0]  [1.0, 0.0]\n",
              "1  villes françaises, qualité l'air meilleure moi...  [1, 0]  [1.0, 0.0]\n",
              "2  cop25, vient s'achever, laisse goût amer certa...  [1, 0]  [1.0, 0.0]\n",
              "3  catherine abreu, climate action network . cop2...  [1, 0]  [1.0, 0.0]\n",
              "4  donné signe clair d'une telle intention 2020. ...  [1, 0]  [1.0, 0.0]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91b1f939-5760-4b4a-9125-5e2f4dab2c00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>président groupe lrem a pris toutes pincettes....</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>villes françaises, qualité l'air meilleure moi...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cop25, vient s'achever, laisse goût amer certa...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>catherine abreu, climate action network . cop2...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>donné signe clair d'une telle intention 2020. ...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91b1f939-5760-4b4a-9125-5e2f4dab2c00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91b1f939-5760-4b4a-9125-5e2f4dab2c00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91b1f939-5760-4b4a-9125-5e2f4dab2c00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test.loc[0]['pred']"
      ],
      "metadata": {
        "id": "gnA03pyUtJoW",
        "outputId": "7f391770-e169-4adc-e05c-225f0eea64a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 0\n",
        "\n",
        "df_test['pred'] = [list() for x in range(len(df_test.index))]\n",
        "\n",
        "for idx,row in df_test.iterrows():\n",
        "  for i in range(row['len_split']): \n",
        "    row['pred'].append(cleaned_df_test.loc[pos]['pred'])\n",
        "    pos += 1"
      ],
      "metadata": {
        "id": "xMtXCnhErx-t"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in df_test.iterrows(): \n",
        "  if row['len_split'] > 1: \n",
        "    print(row['pred'], row['label'])"
      ],
      "metadata": {
        "id": "5-vX1oC8uERf",
        "outputId": "a86f417b-fca7-419d-bab1-c70aca39dff5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': BERTClass(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "metadata": {
        "id": "txBBhkjlIBKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd3e560-a6d3-4dec-e02e-38ac455b6720"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    \n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "GLnlh8IBFxWX"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model = load_checkpoint('checkpoint.pth')"
      ],
      "metadata": {
        "id": "gQt65jD-mB-L"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"hello there\"\n",
        "\n",
        "d = {'data': [news]}\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "test_set = CustomDataset(df, tokenizer, MAX_LEN, is_target = False)"
      ],
      "metadata": {
        "id": "NPga-nfiKE9d"
      },
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_params = {'batch_size': 1,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "_loader = DataLoader(test_set, **_params)"
      ],
      "metadata": {
        "id": "mGFwfI55SlsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model.eval()\n",
        "the_model.to(device)\n",
        "for _,data in enumerate(_loader, 0):\n",
        "  ids = data['ids'].to(device)\n",
        "  mask = data['mask'].to(device)\n",
        "  token_type_ids = data['token_type_ids'].to(device)\n",
        "  \n",
        "  outputs = the_model(ids, mask, token_type_ids)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  print(predicted)"
      ],
      "metadata": {
        "id": "8k115lQfmQoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyK93GVST7bZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}