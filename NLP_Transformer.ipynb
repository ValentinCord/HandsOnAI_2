{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb",
      "authorship_tag": "ABX9TyNdUPb+IFRnWnF1JB5hSp70",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "ndfJjNRbOtqA",
        "outputId": "808e5f19-55aa-44a5-f80a-bf1c4aefeaf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 16 18:00:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0    34W /  70W |   7700MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "MZ_nxGkkO7BB",
        "outputId": "7a317b65-3ac8-4f2b-bab4-38eb54069082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basics \n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# transformers \n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# plot \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# torch \n",
        "import torch\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# nltk \n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "IItKtGo1O8yQ",
        "outputId": "113420bd-ede8-4adf-d241-2f2cd92b9229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGXyKBKhQAVX",
        "outputId": "3c503ab2-cba7-4ecc-bc1c-75715c7c4f57"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture et analyse pandas"
      ],
      "metadata": {
        "id": "quksqXzGSHdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 10\n",
        "VALID_BATCH_SIZE = 10\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "LEN_TEXT = 300\n",
        "OVERLAP = 50"
      ],
      "metadata": {
        "id": "h__VY3DBvT6V"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_train.csv'\n",
        "added_path = '/content/drive/MyDrive/HandOnAI_2_NLP/added_train.csv'\n",
        "test_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_test.csv'\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "df_added = pd.read_csv(added_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# suppression des colonnes inutiles \n",
        "df = df.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "df_added.rename(columns = {'french':'data'}, inplace = True)\n",
        "df_added = df_added.drop(['Unnamed: 0'], axis = 1)\n",
        "df_test = df_test.drop(['Unnamed: 0', 'target_name'], axis = 1)"
      ],
      "metadata": {
        "id": "tiOqzZa_QBHP"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "FWfiMMDWYa7I",
        "outputId": "a92fe66e-1d92-40bc-da79-40f08f2bc245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1458"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_added)"
      ],
      "metadata": {
        "id": "yB74WHi53jOv",
        "outputId": "e5bb475d-e7fe-442d-8cd1-ea5491d322ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11150"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df.append(df_added[:2000], ignore_index=True)"
      ],
      "metadata": {
        "id": "GgqirKqeX8u1"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('french'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    #text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "metadata": {
        "id": "jb8g1SRXMV6Y"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data'] = df['data'].apply(clean_text)\n",
        "df_test['data'] = df_test['data'].apply(clean_text)"
      ],
      "metadata": {
        "id": "MFuS0cn_NznG"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fpbc0ayFONt5",
        "outputId": "517f747f-0d53-49db-fb93-abb29c92ff18"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data  label\n",
              "0  22e jour consécutif grève reconductible contre...      0\n",
              "1  depuis plusieurs mois initiatives chercheurs m...      0\n",
              "2  google vient d'introduire mise jour applicatio...      0\n",
              "3  portrait. chacun s’empresse autour d’elle tand...      0\n",
              "4  « n’y a risque pénurie » carburant a déclaré j...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f02ab65-2e90-4623-9524-84a0a288aec2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22e jour consécutif grève reconductible contre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>depuis plusieurs mois initiatives chercheurs m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>google vient d'introduire mise jour applicatio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>portrait. chacun s’empresse autour d’elle tand...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>« n’y a risque pénurie » carburant a déclaré j...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f02ab65-2e90-4623-9524-84a0a288aec2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f02ab65-2e90-4623-9524-84a0a288aec2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f02ab65-2e90-4623-9524-84a0a288aec2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//(LEN_TEXT - OVERLAP) >0:\n",
        "        n = len(text1.split())//(LEN_TEXT - OVERLAP)\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*(LEN_TEXT - OVERLAP):w*(LEN_TEXT - OVERLAP) + LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total"
      ],
      "metadata": {
        "id": "CsSspiWDNQ89"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_split'] = df['data'].apply(get_split)\n",
        "df['len_split'] = df['text_split'].apply(lambda x: len(x))\n",
        "\n",
        "df_test['text_split'] = df_test['data'].apply(get_split)\n",
        "df_test['len_split'] = df_test['text_split'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "zPkVbv9gNSh-"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['len_split'].value_counts()"
      ],
      "metadata": {
        "id": "BFaerOjcezKm",
        "outputId": "dfcc18e5-f237-4a64-ee50-660ffd3c5920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     1248\n",
              "2      126\n",
              "3       45\n",
              "4       23\n",
              "6        5\n",
              "7        4\n",
              "5        3\n",
              "8        2\n",
              "12       1\n",
              "14       1\n",
              "Name: len_split, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['len_split'].value_counts()"
      ],
      "metadata": {
        "id": "WdJw9CkOfZHP",
        "outputId": "86cedace-2cdf-42e3-ec4f-f8a625056091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     418\n",
              "2      43\n",
              "3      11\n",
              "5       5\n",
              "4       5\n",
              "6       2\n",
              "7       1\n",
              "11      1\n",
              "Name: len_split, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verification du fonctionnement\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if len(row['text_split']) > 1: \n",
        "    print(index)\n",
        "    break\n",
        "\n",
        "print(df['text_split'][31][0].split()[(LEN_TEXT - OVERLAP):])\n",
        "print(df['text_split'][31][1].split()[:OVERLAP])"
      ],
      "metadata": {
        "id": "6UFYbVkZw-5x",
        "outputId": "b98d6aab-57e7-4972-b3b4-99c6fbe2bd49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "['étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour', 'formation', 'lopez', 'bertodano', 'dont', 'strates', 'témoignent', 'période']\n",
            "['étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour', 'formation', 'lopez', 'bertodano', 'dont', 'strates', 'témoignent', 'période']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(df): \n",
        "  train_l = []\n",
        "  label_l = []\n",
        "  for idx,row in df.iterrows():\n",
        "      for l in row['text_split']:\n",
        "          train_l.append(l)\n",
        "          label_l.append([1 if row['label'] == i else 0 for i in range(2)])\n",
        "\n",
        "  return pd.DataFrame({'data':train_l, 'label':label_l})"
      ],
      "metadata": {
        "id": "X0tOshbBOtdh"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = create_df(df)\n",
        "cleaned_df_test = create_df(df_test)"
      ],
      "metadata": {
        "id": "c3Ef_wbQO2DV"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len, is_target = True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = dataframe\n",
        "        self.text = dataframe.data\n",
        "        self.max_len = max_len\n",
        "        if is_target: \n",
        "          self.targets = self.df.label\n",
        "        else: \n",
        "          self.targets = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.targets is None: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "          }\n",
        "        else: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "          }"
      ],
      "metadata": {
        "id": "B1zIS8_5f1km"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tranfo_name = \"cmarkea/distilcamembert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tranfo_name)"
      ],
      "metadata": {
        "id": "d19z9CWe2D7W"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "train_dataset=cleaned_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=cleaned_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(cleaned_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(cleaned_df, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(cleaned_df_test, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "unfGKfEHg0Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687cef60-0265-4991-8e0c-9ca6692d57cf"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (1842, 2)\n",
            "TRAIN Dataset: (1474, 2)\n",
            "TEST Dataset: (368, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "FkinDs9Mj42G"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "      super(BERTClass, self).__init__()\n",
        "      self.l1 = CamembertModel.from_pretrained(tranfo_name)\n",
        "      self.l3 = torch.nn.Linear(768, 2) #2 = binary classification\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      output = self.l3(output_1['pooler_output'])\n",
        "\n",
        "      return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "YI-RQetem1Ou",
        "outputId": "457719eb-af73-477d-806d-2237726a8090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l3): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "cHuUpT28bBFy"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        token_type_ids = data['token_type_ids'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%10==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GkLpQpkrcXj0"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "V1oQxlezm-qh",
        "outputId": "242d2591-3591-43c8-eb14-ad7a91d122ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.6294869184494019\n",
            "Epoch: 0, Loss:  0.9438809752464294\n",
            "Epoch: 0, Loss:  0.6648010611534119\n",
            "Epoch: 0, Loss:  0.4607350528240204\n",
            "Epoch: 0, Loss:  0.2930905818939209\n",
            "Epoch: 0, Loss:  0.38905957341194153\n",
            "Epoch: 0, Loss:  0.10348131507635117\n",
            "Epoch: 0, Loss:  0.3762352466583252\n",
            "Epoch: 0, Loss:  0.45398011803627014\n",
            "Epoch: 0, Loss:  0.08011548966169357\n",
            "Epoch: 0, Loss:  0.5656986236572266\n",
            "Epoch: 0, Loss:  0.28913888335227966\n",
            "Epoch: 0, Loss:  0.10057342052459717\n",
            "Epoch: 0, Loss:  0.11074121296405792\n",
            "Epoch: 0, Loss:  0.0827561765909195\n",
            "Epoch: 0, Loss:  0.0883408784866333\n",
            "Epoch: 0, Loss:  0.08385002613067627\n",
            "Epoch: 0, Loss:  0.04390465095639229\n",
            "Epoch: 0, Loss:  0.06428507715463638\n",
            "Epoch: 1, Loss:  0.03863358497619629\n",
            "Epoch: 1, Loss:  0.13830403983592987\n",
            "Epoch: 1, Loss:  0.04863704368472099\n",
            "Epoch: 1, Loss:  0.033583205193281174\n",
            "Epoch: 1, Loss:  0.050243403762578964\n",
            "Epoch: 1, Loss:  0.03810238093137741\n",
            "Epoch: 1, Loss:  0.02445991151034832\n",
            "Epoch: 1, Loss:  0.3660668432712555\n",
            "Epoch: 1, Loss:  0.7196770310401917\n",
            "Epoch: 1, Loss:  0.039662860333919525\n",
            "Epoch: 1, Loss:  0.03874708339571953\n",
            "Epoch: 1, Loss:  0.04534950852394104\n",
            "Epoch: 1, Loss:  0.024990525096654892\n",
            "Epoch: 1, Loss:  0.053835052996873856\n",
            "Epoch: 1, Loss:  0.04463685676455498\n",
            "Epoch: 1, Loss:  0.03253436088562012\n",
            "Epoch: 1, Loss:  0.04811617359519005\n",
            "Epoch: 1, Loss:  0.3462970554828644\n",
            "Epoch: 1, Loss:  0.10589276999235153\n",
            "Epoch: 2, Loss:  0.03586031496524811\n",
            "Epoch: 2, Loss:  0.02803872898221016\n",
            "Epoch: 2, Loss:  0.4341060221195221\n",
            "Epoch: 2, Loss:  0.030711054801940918\n",
            "Epoch: 2, Loss:  0.041863709688186646\n",
            "Epoch: 2, Loss:  0.022863373160362244\n",
            "Epoch: 2, Loss:  0.19123409688472748\n",
            "Epoch: 2, Loss:  0.02043084427714348\n",
            "Epoch: 2, Loss:  0.0317082516849041\n",
            "Epoch: 2, Loss:  0.017274534329771996\n",
            "Epoch: 2, Loss:  0.3929801881313324\n",
            "Epoch: 2, Loss:  0.03745966777205467\n",
            "Epoch: 2, Loss:  0.01651216857135296\n",
            "Epoch: 2, Loss:  0.01676838845014572\n",
            "Epoch: 2, Loss:  0.06829272210597992\n",
            "Epoch: 2, Loss:  0.3874588906764984\n",
            "Epoch: 2, Loss:  0.14166122674942017\n",
            "Epoch: 2, Loss:  0.018723443150520325\n",
            "Epoch: 2, Loss:  0.023656759411096573\n",
            "Epoch: 3, Loss:  0.013261720538139343\n",
            "Epoch: 3, Loss:  0.04589042067527771\n",
            "Epoch: 3, Loss:  0.11666648834943771\n",
            "Epoch: 3, Loss:  0.07684203237295151\n",
            "Epoch: 3, Loss:  0.018992362543940544\n",
            "Epoch: 3, Loss:  0.06400191783905029\n",
            "Epoch: 3, Loss:  0.318901389837265\n",
            "Epoch: 3, Loss:  0.09581979364156723\n",
            "Epoch: 3, Loss:  0.0189164187759161\n",
            "Epoch: 3, Loss:  0.0138672711327672\n",
            "Epoch: 3, Loss:  0.6911110281944275\n",
            "Epoch: 3, Loss:  0.1805364340543747\n",
            "Epoch: 3, Loss:  0.13538511097431183\n",
            "Epoch: 3, Loss:  0.02173694409430027\n",
            "Epoch: 3, Loss:  0.2752467095851898\n",
            "Epoch: 3, Loss:  0.0693831667304039\n",
            "Epoch: 3, Loss:  0.6310397982597351\n",
            "Epoch: 3, Loss:  0.020976660773158073\n",
            "Epoch: 3, Loss:  0.0069075520150363445\n",
            "Epoch: 4, Loss:  0.018434135243296623\n",
            "Epoch: 4, Loss:  0.012973221018910408\n",
            "Epoch: 4, Loss:  0.007983037270605564\n",
            "Epoch: 4, Loss:  0.10376741737127304\n",
            "Epoch: 4, Loss:  0.014597526751458645\n",
            "Epoch: 4, Loss:  0.5807456374168396\n",
            "Epoch: 4, Loss:  0.039125945419073105\n",
            "Epoch: 4, Loss:  0.017677364870905876\n",
            "Epoch: 4, Loss:  0.02218313328921795\n",
            "Epoch: 4, Loss:  0.011201980523765087\n",
            "Epoch: 4, Loss:  0.014403666369616985\n",
            "Epoch: 4, Loss:  0.01205905806273222\n",
            "Epoch: 4, Loss:  0.008496289141476154\n",
            "Epoch: 4, Loss:  0.061821695417165756\n",
            "Epoch: 4, Loss:  0.008647081442177296\n",
            "Epoch: 4, Loss:  0.009729313664138317\n",
            "Epoch: 4, Loss:  0.008215615525841713\n",
            "Epoch: 4, Loss:  0.0074599371291697025\n",
            "Epoch: 4, Loss:  0.008500711992383003\n",
            "Epoch: 5, Loss:  0.2054527848958969\n",
            "Epoch: 5, Loss:  0.32707470655441284\n",
            "Epoch: 5, Loss:  0.007919778116047382\n",
            "Epoch: 5, Loss:  0.012959952466189861\n",
            "Epoch: 5, Loss:  0.00812110211700201\n",
            "Epoch: 5, Loss:  0.010298974812030792\n",
            "Epoch: 5, Loss:  0.03704040125012398\n",
            "Epoch: 5, Loss:  0.005608706269413233\n",
            "Epoch: 5, Loss:  0.00900009274482727\n",
            "Epoch: 5, Loss:  0.004456040915101767\n",
            "Epoch: 5, Loss:  0.008329176343977451\n",
            "Epoch: 5, Loss:  0.022902289405465126\n",
            "Epoch: 5, Loss:  0.004836522974073887\n",
            "Epoch: 5, Loss:  0.0042255716398358345\n",
            "Epoch: 5, Loss:  0.004012258257716894\n",
            "Epoch: 5, Loss:  0.007679525297135115\n",
            "Epoch: 5, Loss:  0.011253834702074528\n",
            "Epoch: 5, Loss:  0.017455650493502617\n",
            "Epoch: 5, Loss:  0.00845587719231844\n",
            "Epoch: 6, Loss:  0.006045559886842966\n",
            "Epoch: 6, Loss:  0.004397904966026545\n",
            "Epoch: 6, Loss:  0.010477334260940552\n",
            "Epoch: 6, Loss:  0.005131799727678299\n",
            "Epoch: 6, Loss:  0.0044641862623393536\n",
            "Epoch: 6, Loss:  0.009664478711783886\n",
            "Epoch: 6, Loss:  0.007890834473073483\n",
            "Epoch: 6, Loss:  0.004873740486800671\n",
            "Epoch: 6, Loss:  0.004513534251600504\n",
            "Epoch: 6, Loss:  0.00338541716337204\n",
            "Epoch: 6, Loss:  0.006859361659735441\n",
            "Epoch: 6, Loss:  0.00305615970864892\n",
            "Epoch: 6, Loss:  0.047022026032209396\n",
            "Epoch: 6, Loss:  0.016403818503022194\n",
            "Epoch: 6, Loss:  0.002999440534040332\n",
            "Epoch: 6, Loss:  0.004904497880488634\n",
            "Epoch: 6, Loss:  0.004560999572277069\n",
            "Epoch: 6, Loss:  0.19639720022678375\n",
            "Epoch: 6, Loss:  0.004765164107084274\n",
            "Epoch: 7, Loss:  0.003064371645450592\n",
            "Epoch: 7, Loss:  0.003178209764882922\n",
            "Epoch: 7, Loss:  0.0034187943674623966\n",
            "Epoch: 7, Loss:  0.0029605315066874027\n",
            "Epoch: 7, Loss:  0.0032168508041650057\n",
            "Epoch: 7, Loss:  0.0031403438188135624\n",
            "Epoch: 7, Loss:  0.002488353755325079\n",
            "Epoch: 7, Loss:  0.002399720484390855\n",
            "Epoch: 7, Loss:  0.0034120462369173765\n",
            "Epoch: 7, Loss:  0.003287901869043708\n",
            "Epoch: 7, Loss:  0.0044299825094640255\n",
            "Epoch: 7, Loss:  0.005180473905056715\n",
            "Epoch: 7, Loss:  0.4850289523601532\n",
            "Epoch: 7, Loss:  0.0030752536840736866\n",
            "Epoch: 7, Loss:  0.004178192000836134\n",
            "Epoch: 7, Loss:  0.002465652534738183\n",
            "Epoch: 7, Loss:  0.003113523358479142\n",
            "Epoch: 7, Loss:  0.0028949379920959473\n",
            "Epoch: 7, Loss:  0.0038956606294959784\n",
            "Epoch: 8, Loss:  0.012229040265083313\n",
            "Epoch: 8, Loss:  0.0017082194099202752\n",
            "Epoch: 8, Loss:  0.0018402375280857086\n",
            "Epoch: 8, Loss:  0.0021481530275195837\n",
            "Epoch: 8, Loss:  0.002011245349422097\n",
            "Epoch: 8, Loss:  0.001606167177669704\n",
            "Epoch: 8, Loss:  0.004354862961918116\n",
            "Epoch: 8, Loss:  0.0022390957456082106\n",
            "Epoch: 8, Loss:  0.002908204449340701\n",
            "Epoch: 8, Loss:  0.001799353281967342\n",
            "Epoch: 8, Loss:  0.0019231528276577592\n",
            "Epoch: 8, Loss:  0.0015187928220257163\n",
            "Epoch: 8, Loss:  0.0016789805376902223\n",
            "Epoch: 8, Loss:  0.0026004635728895664\n",
            "Epoch: 8, Loss:  0.0016192445764318109\n",
            "Epoch: 8, Loss:  0.016934717074036598\n",
            "Epoch: 8, Loss:  0.0017666217172518373\n",
            "Epoch: 8, Loss:  0.0014787748223170638\n",
            "Epoch: 8, Loss:  0.0020095924846827984\n",
            "Epoch: 9, Loss:  0.0013172775506973267\n",
            "Epoch: 9, Loss:  0.0012554218992590904\n",
            "Epoch: 9, Loss:  0.0018323156982660294\n",
            "Epoch: 9, Loss:  0.0012901778100058436\n",
            "Epoch: 9, Loss:  0.0022009953390806913\n",
            "Epoch: 9, Loss:  0.0013980669900774956\n",
            "Epoch: 9, Loss:  0.003194232238456607\n",
            "Epoch: 9, Loss:  0.001516353222541511\n",
            "Epoch: 9, Loss:  0.0014416610356420279\n",
            "Epoch: 9, Loss:  0.0019814246334135532\n",
            "Epoch: 9, Loss:  0.0011838199570775032\n",
            "Epoch: 9, Loss:  0.0021614523138850927\n",
            "Epoch: 9, Loss:  0.0012513045221567154\n",
            "Epoch: 9, Loss:  0.0012412472860887647\n",
            "Epoch: 9, Loss:  0.001222627586685121\n",
            "Epoch: 9, Loss:  0.001297765295021236\n",
            "Epoch: 9, Loss:  0.0029182780999690294\n",
            "Epoch: 9, Loss:  0.0011402465170249343\n",
            "Epoch: 9, Loss:  0.0011522247223183513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation():\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "      for _, data in enumerate(testing_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "        m = torch.nn.Softmax(dim=1)\n",
        "        fin_outputs.extend(torch.round(m(outputs)).cpu().detach().numpy().tolist())\n",
        "\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "HqGsmQgV7IJ0"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "outputs, targets = validation()\n",
        "accuracy = metrics.accuracy_score(targets, outputs)\n",
        "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "qqjHEDooHz4i",
        "outputId": "23fba3c7-4485-441d-ffdd-e6f18715e973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.9722222222222222\n",
            "F1 Score (Micro) = 0.9722222222222222\n",
            "F1 Score (Macro) = 0.9690112737724694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test['pred'] = outputs\n",
        "cleaned_df_test.head()"
      ],
      "metadata": {
        "id": "V1A2NZ6deQiu",
        "outputId": "955f6d97-90f6-43fd-a8f3-f2da89b13abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data   label        pred\n",
              "0  président groupe lrem a pris toutes pincettes....  [1, 0]  [1.0, 0.0]\n",
              "1  villes françaises qualité l'air meilleure moin...  [1, 0]  [1.0, 0.0]\n",
              "2  cop25 vient s'achever laisse goût amer certain...  [1, 0]  [1.0, 0.0]\n",
              "3  action network . cop25 occasion « ratée » répo...  [1, 0]  [1.0, 0.0]\n",
              "4  2020. évidemment états-unis quitteront l'accor...  [1, 0]  [1.0, 0.0]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9da1963b-7d46-4d1e-b145-0b1709347093\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>président groupe lrem a pris toutes pincettes....</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>villes françaises qualité l'air meilleure moin...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cop25 vient s'achever laisse goût amer certain...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>action network . cop25 occasion « ratée » répo...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020. évidemment états-unis quitteront l'accor...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9da1963b-7d46-4d1e-b145-0b1709347093')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9da1963b-7d46-4d1e-b145-0b1709347093 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9da1963b-7d46-4d1e-b145-0b1709347093');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test.loc[0]['pred']"
      ],
      "metadata": {
        "id": "gnA03pyUtJoW",
        "outputId": "e5227d5e-e721-4e2c-bfd3-34e231084e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 0\n",
        "\n",
        "df_test['pred'] = [list() for x in range(len(df_test.index))]\n",
        "\n",
        "for idx,row in df_test.iterrows():\n",
        "  for i in range(row['len_split']): \n",
        "    row['pred'].append(cleaned_df_test.loc[pos]['pred'])\n",
        "    pos += 1"
      ],
      "metadata": {
        "id": "xMtXCnhErx-t"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in df_test.iterrows(): \n",
        "  if row['len_split'] > 1: \n",
        "    print(row['pred'], row['label'])"
      ],
      "metadata": {
        "id": "5-vX1oC8uERf",
        "outputId": "d038e829-f0cd-4fe5-8336-0e9a76d05b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n",
            "[[1.0, 0.0], [1.0, 0.0]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': BERTClass(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "metadata": {
        "id": "txBBhkjlIBKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc576202-c928-4257-b6da-bf2e39b0b859"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    \n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "GLnlh8IBFxWX"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model = load_checkpoint('checkpoint.pth')"
      ],
      "metadata": {
        "id": "gQt65jD-mB-L"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"hello there\"\n",
        "\n",
        "d = {'data': [news]}\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "test_set = CustomDataset(df, tokenizer, MAX_LEN, is_target = False)"
      ],
      "metadata": {
        "id": "NPga-nfiKE9d"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_params = {'batch_size': 1,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "_loader = DataLoader(test_set, **_params)"
      ],
      "metadata": {
        "id": "mGFwfI55SlsQ"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model.eval()\n",
        "the_model.to(device)\n",
        "for _,data in enumerate(_loader, 0):\n",
        "  ids = data['ids'].to(device)\n",
        "  mask = data['mask'].to(device)\n",
        "  token_type_ids = data['token_type_ids'].to(device)\n",
        "  \n",
        "  outputs = the_model(ids, mask, token_type_ids)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  print(predicted)"
      ],
      "metadata": {
        "id": "8k115lQfmQoe",
        "outputId": "d1bd472a-32c3-43ea-9b3b-f1c1d9233802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyK93GVST7bZ"
      },
      "execution_count": 181,
      "outputs": []
    }
  ]
}