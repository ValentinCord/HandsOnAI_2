{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb",
      "authorship_tag": "ABX9TyM0OhqmUrWwIJr+7IPXVeet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span> NLP : Entrainnement et sauvegarde du modèle </span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "ye36lI82y9VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Installations](#section-1)\n",
        "* [Imports](#section-2)\n",
        "* [Choix des paramètres](#section-3)\n",
        "* [Lecture des données](#section-4)\n",
        "* [Preprocessing](#section-5)\n",
        "* [Création du modèle](#section-6)\n",
        "* [Entrainement du modèle](#section-7)\n",
        "* [Prédiction des données](#section-8)\n",
        "* [Sauvegarde du modèle](#section-9)\n",
        "* [Test du modèle](#section-10)"
      ],
      "metadata": {
        "id": "r3b3mz3VzLwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-1\"></a>\n",
        "# <span>1. Installation des packages</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "76dtzVzXzQ8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ndfJjNRbOtqA",
        "outputId": "055cfbc0-41bb-4419-d425-fcd389ca8a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 21 20:25:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    30W /  70W |  14938MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data\n",
        "\n",
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span>2. Imports </span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "KESAm8EZyjNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basics \n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# transformers \n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# plot \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# torch \n",
        "import torch\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# nltk \n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "IItKtGo1O8yQ",
        "outputId": "5cb78864-2fe0-4520-e8be-d8de621d6825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "fGXyKBKhQAVX",
        "outputId": "b697b522-1b34-48d1-d15a-f37b34ee18c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-3\"></a>\n",
        "# <span>3. Choix des paramètres</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "\n",
        "<p style=\"text-align:justify;padding:20px;\"> Dans cette section, nous pouvons paramétriser notre modèle. Pour cela, on disposible de plusieurs paramètres. Parmis ces paramètres, on retrouve le choix de fenètre, le batchSize, le pas d'apprentissage et le nombre d'épochs. </p>"
      ],
      "metadata": {
        "id": "2-QTduv_z_sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 10\n",
        "VALID_BATCH_SIZE = 10\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "LEN_TEXT = 300\n",
        "OVERLAP = 50\n",
        "\n",
        "DONNEE_AJOUTEES = 1000\n",
        "\n",
        "TRANSFORMER_NAME = \"cmarkea/distilcamembert-base\"\n",
        "TRAIN_SIZE = 0.8"
      ],
      "metadata": {
        "id": "Wxi7T3Aa0mVT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-4\"></a>\n",
        "# <span>4. Lecture des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "quksqXzGSHdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_train.csv'\n",
        "added_path = '/content/drive/MyDrive/HandOnAI_2_NLP/added_train.csv'\n",
        "test_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_test.csv'\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "df_added = pd.read_csv(added_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# suppression des colonnes inutiles \n",
        "df = df.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "df_added.rename(columns = {'french':'data'}, inplace = True)\n",
        "df_added = df_added.drop(['Unnamed: 0'], axis = 1)\n",
        "df_test = df_test.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "\n",
        "df = df.append(df_added[:DONNEE_AJOUTEES], ignore_index=True)"
      ],
      "metadata": {
        "id": "tiOqzZa_QBHP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-5\"></a>\n",
        "# <span>5. Preprocessing</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p style=\"text-align:justify;padding:20px;\"> La partie preprocessing peut etre scindée en plusieurs étapes. En premier, nous allons appliquer un nettoyage de données. Suite à ce nettoyage, les données seront convertis dans le format adéquat. </p>\n",
        "\n"
      ],
      "metadata": {
        "id": "lHZiX4aQ1ArO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.1 Nettoyage de données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "\n",
        "1.   Suppression des stopwords : les stopwords sont des mots qui n'apportent pas d'informations supplémentaires au texte. Afin de réduire la taille des news, on pourrait éffectuer la suppression de ceux-ci.\n",
        "2.   Suppression des caractères spéciaux : en regardant plusieurs news, nous avons constaté qu'il y avait plusieurs caractères spéciaux. N'apportant aucune information supplémentaires, nous pouvons les supprimer. "
      ],
      "metadata": {
        "id": "jjRFdSHk29uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('french'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    #text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "metadata": {
        "id": "jb8g1SRXMV6Y"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data'] = df['data'].apply(clean_text)\n",
        "df_test['data'] = df_test['data'].apply(clean_text)\n",
        "\n",
        "df = df.drop(df.index[1136])\n",
        "df = df.reset_index()"
      ],
      "metadata": {
        "id": "MFuS0cn_NznG"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.2 Découpage des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "Txki6c5y3oYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//(LEN_TEXT - OVERLAP) >0:\n",
        "        n = len(text1.split())//(LEN_TEXT - OVERLAP)\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*(LEN_TEXT - OVERLAP):w*(LEN_TEXT - OVERLAP) + LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total"
      ],
      "metadata": {
        "id": "CsSspiWDNQ89"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_split'] = df['data'].apply(get_split)\n",
        "df['len_split'] = df['text_split'].apply(lambda x: len(x))\n",
        "\n",
        "df_test['text_split'] = df_test['data'].apply(get_split)\n",
        "df_test['len_split'] = df_test['text_split'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "zPkVbv9gNSh-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "  if len(row['text_split']) > 1: \n",
        "    print(index)\n",
        "    break\n",
        "\n",
        "print(df['text_split'][31][0].split()[(LEN_TEXT - OVERLAP):])\n",
        "print(df['text_split'][31][1].split()[:OVERLAP])"
      ],
      "metadata": {
        "id": "6UFYbVkZw-5x",
        "outputId": "03303e91-6d7e-4f96-d4e0-cd3eb08e4ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "['étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour', 'formation', 'lopez', 'bertodano', 'dont', 'strates', 'témoignent', 'période']\n",
            "['étudiants', \"l'université\", 'carleton', 'lors', \"l'expédition\", 'students', 'ice', 'antarctic', '2011.', \"l'équipe\", 'visite', 'îles', 'déception', 'seymour.', '©', 'musée', 'canadien', 'nature', 'mémoire', 'isotopes', 'calcium', 'menés', 'benjamin', 'linzmeier', 'andrew', 'd.', 'jacobson', \"l'université\", 'northwestern', 'chicago', 'chercheurs', 'basé', 'leurs', 'travaux', 'collecte', 'fossiles', 'retrouvés', 'formation', 'géologique', 'célèbre', 'trouve', \"l'île\", 'seymour', 'formation', 'lopez', 'bertodano', 'dont', 'strates', 'témoignent', 'période']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.3 Reformulation du labels</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "8Lr3VKvG4e_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(df): \n",
        "  train_l = []\n",
        "  label_l = []\n",
        "  for idx,row in df.iterrows():\n",
        "      for l in row['text_split']:\n",
        "          train_l.append(l)\n",
        "          label_l.append([1 if row['label'] == i else 0 for i in range(2)])\n",
        "\n",
        "  return pd.DataFrame({'data':train_l, 'label':label_l})"
      ],
      "metadata": {
        "id": "X0tOshbBOtdh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = create_df(df)\n",
        "cleaned_df_test = create_df(df_test)"
      ],
      "metadata": {
        "id": "c3Ef_wbQO2DV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.4 Création du dataset</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "fUwS-dIw4ssX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len, is_target = True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = dataframe\n",
        "        self.text = dataframe.data\n",
        "        self.max_len = max_len\n",
        "        if is_target: \n",
        "          self.targets = self.df.label\n",
        "        else: \n",
        "          self.targets = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.targets is None: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "          }\n",
        "        else: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "          }"
      ],
      "metadata": {
        "id": "B1zIS8_5f1km"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_NAME)\n",
        "\n",
        "train_dataset = cleaned_df.sample(frac=TRAIN_SIZE,random_state=200)\n",
        "test_dataset = cleaned_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(cleaned_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(cleaned_df, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(cleaned_df_test, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "unfGKfEHg0Ir",
        "outputId": "00044fe9-fc4c-4d2b-c4e3-67d8b8479521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (2828, 2)\n",
            "TRAIN Dataset: (2262, 2)\n",
            "TEST Dataset: (566, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.5 Création du dataloader</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "klqYDdm45g5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "FkinDs9Mj42G"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-6\"></a>\n",
        "# <span>6. Création du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "XZMYZMWE5wcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "      super(BERTClass, self).__init__()\n",
        "      self.l1 = CamembertModel.from_pretrained(TRANSFORMER_NAME)\n",
        "      self.l3 = torch.nn.Linear(768, 2) #2 = binary classification\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      output = self.l3(output_1['pooler_output'])\n",
        "\n",
        "      return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "YI-RQetem1Ou",
        "outputId": "09125524-48f7-462a-fc61-db44769b594c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l3): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "cHuUpT28bBFy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        token_type_ids = data['token_type_ids'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%10==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GkLpQpkrcXj0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-7\"></a>\n",
        "# <span>7. Entrainement du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "QgHnsZNE6D_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "V1oQxlezm-qh",
        "outputId": "09f90c42-88de-468d-d32a-164642adb073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.7068637609481812\n",
            "Epoch: 0, Loss:  0.6194339394569397\n",
            "Epoch: 0, Loss:  0.415027379989624\n",
            "Epoch: 0, Loss:  0.4626781642436981\n",
            "Epoch: 0, Loss:  0.5663694739341736\n",
            "Epoch: 0, Loss:  0.2746686339378357\n",
            "Epoch: 0, Loss:  0.7220785617828369\n",
            "Epoch: 0, Loss:  0.3618438243865967\n",
            "Epoch: 0, Loss:  0.4927475154399872\n",
            "Epoch: 0, Loss:  0.6343444585800171\n",
            "Epoch: 0, Loss:  0.9435674548149109\n",
            "Epoch: 0, Loss:  0.4976455867290497\n",
            "Epoch: 0, Loss:  0.36431241035461426\n",
            "Epoch: 0, Loss:  0.1345483511686325\n",
            "Epoch: 0, Loss:  0.15313038229942322\n",
            "Epoch: 0, Loss:  0.41610679030418396\n",
            "Epoch: 0, Loss:  0.41350966691970825\n",
            "Epoch: 0, Loss:  0.33707308769226074\n",
            "Epoch: 0, Loss:  0.6269976496696472\n",
            "Epoch: 0, Loss:  0.42266079783439636\n",
            "Epoch: 0, Loss:  0.2725239098072052\n",
            "Epoch: 0, Loss:  0.7207757830619812\n",
            "Epoch: 0, Loss:  0.27315789461135864\n",
            "Epoch: 0, Loss:  0.2660796642303467\n",
            "Epoch: 0, Loss:  0.34000059962272644\n",
            "Epoch: 0, Loss:  0.4872133433818817\n",
            "Epoch: 0, Loss:  0.10868111997842789\n",
            "Epoch: 0, Loss:  0.16823099553585052\n",
            "Epoch: 0, Loss:  0.21104541420936584\n",
            "Epoch: 1, Loss:  0.3412635922431946\n",
            "Epoch: 1, Loss:  0.41909345984458923\n",
            "Epoch: 1, Loss:  0.10245960205793381\n",
            "Epoch: 1, Loss:  0.32911109924316406\n",
            "Epoch: 1, Loss:  0.0713125690817833\n",
            "Epoch: 1, Loss:  0.23842881619930267\n",
            "Epoch: 1, Loss:  0.1525668054819107\n",
            "Epoch: 1, Loss:  0.10971003025770187\n",
            "Epoch: 1, Loss:  0.3524777591228485\n",
            "Epoch: 1, Loss:  0.19731184840202332\n",
            "Epoch: 1, Loss:  0.33147045969963074\n",
            "Epoch: 1, Loss:  0.08418954163789749\n",
            "Epoch: 1, Loss:  0.40505358576774597\n",
            "Epoch: 1, Loss:  0.20015250146389008\n",
            "Epoch: 1, Loss:  0.2689598798751831\n",
            "Epoch: 1, Loss:  0.29618141055107117\n",
            "Epoch: 1, Loss:  0.32577821612358093\n",
            "Epoch: 1, Loss:  0.2296660989522934\n",
            "Epoch: 1, Loss:  0.10248156636953354\n",
            "Epoch: 1, Loss:  0.09840148687362671\n",
            "Epoch: 1, Loss:  0.1710456758737564\n",
            "Epoch: 1, Loss:  0.05186191946268082\n",
            "Epoch: 1, Loss:  0.08765915781259537\n",
            "Epoch: 1, Loss:  0.057673145085573196\n",
            "Epoch: 1, Loss:  0.7343436479568481\n",
            "Epoch: 1, Loss:  0.3650045096874237\n",
            "Epoch: 1, Loss:  0.18217149376869202\n",
            "Epoch: 1, Loss:  0.5382944345474243\n",
            "Epoch: 1, Loss:  0.45001107454299927\n",
            "Epoch: 2, Loss:  0.07258021086454391\n",
            "Epoch: 2, Loss:  0.34189674258232117\n",
            "Epoch: 2, Loss:  0.14564697444438934\n",
            "Epoch: 2, Loss:  0.04661627858877182\n",
            "Epoch: 2, Loss:  0.09241185337305069\n",
            "Epoch: 2, Loss:  0.2248823493719101\n",
            "Epoch: 2, Loss:  0.4795387387275696\n",
            "Epoch: 2, Loss:  0.009474396705627441\n",
            "Epoch: 2, Loss:  0.1503353863954544\n",
            "Epoch: 2, Loss:  0.13302521407604218\n",
            "Epoch: 2, Loss:  0.07357945293188095\n",
            "Epoch: 2, Loss:  0.03420170769095421\n",
            "Epoch: 2, Loss:  0.04965288192033768\n",
            "Epoch: 2, Loss:  0.03535391762852669\n",
            "Epoch: 2, Loss:  0.02118813805282116\n",
            "Epoch: 2, Loss:  0.01314885076135397\n",
            "Epoch: 2, Loss:  0.33806002140045166\n",
            "Epoch: 2, Loss:  0.3195824921131134\n",
            "Epoch: 2, Loss:  0.15996523201465607\n",
            "Epoch: 2, Loss:  0.032938193529844284\n",
            "Epoch: 2, Loss:  0.026517439633607864\n",
            "Epoch: 2, Loss:  0.11672525852918625\n",
            "Epoch: 2, Loss:  0.40619418025016785\n",
            "Epoch: 2, Loss:  0.4054485857486725\n",
            "Epoch: 2, Loss:  0.03454769775271416\n",
            "Epoch: 2, Loss:  1.029758334159851\n",
            "Epoch: 2, Loss:  0.04266679286956787\n",
            "Epoch: 2, Loss:  0.07131487131118774\n",
            "Epoch: 2, Loss:  0.09156569093465805\n",
            "Epoch: 3, Loss:  0.07188113033771515\n",
            "Epoch: 3, Loss:  0.07639308273792267\n",
            "Epoch: 3, Loss:  0.46266475319862366\n",
            "Epoch: 3, Loss:  0.3747161626815796\n",
            "Epoch: 3, Loss:  0.01621970161795616\n",
            "Epoch: 3, Loss:  0.03588842228055\n",
            "Epoch: 3, Loss:  0.04258577153086662\n",
            "Epoch: 3, Loss:  0.13111285865306854\n",
            "Epoch: 3, Loss:  0.021863475441932678\n",
            "Epoch: 3, Loss:  0.005362436641007662\n",
            "Epoch: 3, Loss:  0.01148251723498106\n",
            "Epoch: 3, Loss:  0.03857867419719696\n",
            "Epoch: 3, Loss:  0.00536331394687295\n",
            "Epoch: 3, Loss:  0.45068588852882385\n",
            "Epoch: 3, Loss:  0.01881599985063076\n",
            "Epoch: 3, Loss:  0.01013619638979435\n",
            "Epoch: 3, Loss:  0.009364979341626167\n",
            "Epoch: 3, Loss:  0.013655821792781353\n",
            "Epoch: 3, Loss:  0.3670840859413147\n",
            "Epoch: 3, Loss:  0.5547565817832947\n",
            "Epoch: 3, Loss:  0.06298547238111496\n",
            "Epoch: 3, Loss:  0.1810382753610611\n",
            "Epoch: 3, Loss:  0.06758049875497818\n",
            "Epoch: 3, Loss:  0.012226808816194534\n",
            "Epoch: 3, Loss:  0.07399595528841019\n",
            "Epoch: 3, Loss:  0.15311400592327118\n",
            "Epoch: 3, Loss:  0.06750787794589996\n",
            "Epoch: 3, Loss:  0.07925551384687424\n",
            "Epoch: 3, Loss:  0.3795209527015686\n",
            "Epoch: 4, Loss:  0.11294249445199966\n",
            "Epoch: 4, Loss:  0.00743204727768898\n",
            "Epoch: 4, Loss:  0.026685072109103203\n",
            "Epoch: 4, Loss:  0.32884058356285095\n",
            "Epoch: 4, Loss:  0.016607245430350304\n",
            "Epoch: 4, Loss:  0.04324540123343468\n",
            "Epoch: 4, Loss:  0.20258836448192596\n",
            "Epoch: 4, Loss:  0.09823027998209\n",
            "Epoch: 4, Loss:  0.06844089925289154\n",
            "Epoch: 4, Loss:  0.04972107335925102\n",
            "Epoch: 4, Loss:  0.18693725764751434\n",
            "Epoch: 4, Loss:  0.04242944344878197\n",
            "Epoch: 4, Loss:  0.08764516562223434\n",
            "Epoch: 4, Loss:  0.01285980548709631\n",
            "Epoch: 4, Loss:  0.016947031021118164\n",
            "Epoch: 4, Loss:  0.0167375598102808\n",
            "Epoch: 4, Loss:  0.010752449743449688\n",
            "Epoch: 4, Loss:  0.0312822125852108\n",
            "Epoch: 4, Loss:  0.008742081001400948\n",
            "Epoch: 4, Loss:  0.007685288321226835\n",
            "Epoch: 4, Loss:  0.0056141214445233345\n",
            "Epoch: 4, Loss:  0.003424725029617548\n",
            "Epoch: 4, Loss:  0.1162090077996254\n",
            "Epoch: 4, Loss:  0.09502019733190536\n",
            "Epoch: 4, Loss:  0.11423003673553467\n",
            "Epoch: 4, Loss:  0.019409460946917534\n",
            "Epoch: 4, Loss:  0.046138178557157516\n",
            "Epoch: 4, Loss:  0.01685895398259163\n",
            "Epoch: 4, Loss:  0.05352061986923218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-8\"></a>\n",
        "# <span>8. Prédiction des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "09BR8pAw6Tv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation():\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "      for _, data in enumerate(testing_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "        m = torch.nn.Softmax(dim=1)\n",
        "        fin_outputs.extend(torch.round(m(outputs)).cpu().detach().numpy().tolist())\n",
        "\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "HqGsmQgV7IJ0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, targets = validation()\n",
        "accuracy = metrics.accuracy_score(targets, outputs)\n",
        "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "qqjHEDooHz4i",
        "outputId": "aac5f35d-1a27-4a38-dbef-9f3207fffcb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.9689542483660131\n",
            "F1 Score (Micro) = 0.9689542483660131\n",
            "F1 Score (Macro) = 0.9659057923208867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test['pred'] = outputs\n",
        "cleaned_df_test.head()"
      ],
      "metadata": {
        "id": "V1A2NZ6deQiu",
        "outputId": "d95b94dd-a6d7-4bf2-c35a-0079e578a7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data   label        pred\n",
              "0  président groupe lrem a pris toutes pincettes....  [1, 0]  [1.0, 0.0]\n",
              "1  villes françaises qualité l'air meilleure moin...  [1, 0]  [1.0, 0.0]\n",
              "2  cop25 vient s'achever laisse goût amer certain...  [1, 0]  [1.0, 0.0]\n",
              "3  action network . cop25 occasion « ratée » répo...  [1, 0]  [1.0, 0.0]\n",
              "4  2020. évidemment états-unis quitteront l'accor...  [1, 0]  [1.0, 0.0]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9afbd81-afc8-4648-b8a0-12910854e120\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>président groupe lrem a pris toutes pincettes....</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>villes françaises qualité l'air meilleure moin...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cop25 vient s'achever laisse goût amer certain...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>action network . cop25 occasion « ratée » répo...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020. évidemment états-unis quitteront l'accor...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9afbd81-afc8-4648-b8a0-12910854e120')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9afbd81-afc8-4648-b8a0-12910854e120 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9afbd81-afc8-4648-b8a0-12910854e120');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 0\n",
        "df_test['pred'] = [list() for x in range(len(df_test.index))]\n",
        "for idx,row in df_test.iterrows():\n",
        "  for i in range(row['len_split']): \n",
        "    row['pred'].append(cleaned_df_test.loc[pos]['pred'])\n",
        "    pos += 1"
      ],
      "metadata": {
        "id": "xMtXCnhErx-t"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for idx, row in df_test.iterrows(): \n",
        "#   if row['len_split'] > 1: \n",
        "#     print(row['pred'], row['label'])"
      ],
      "metadata": {
        "id": "5-vX1oC8uERf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['prediction'] = df_test['pred'].apply(lambda x: [1, 0] if np.argmax(np.sum(x, axis = 0)) == 0 else [0, 1])\n",
        "df_test['label_pred'] = df_test['pred'].apply(lambda x: np.argmax(np.sum(x, axis = 0)))"
      ],
      "metadata": {
        "id": "LAIdo60rp9Rb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(df_test['label_pred'], df_test['label'])\n",
        "f1_score_micro = metrics.f1_score(df_test['label_pred'], df_test['label'], average='micro')\n",
        "f1_score_macro = metrics.f1_score(df_test['label_pred'], df_test['label'], average='macro')\n",
        "print(f\"Accuracy Score = {accuracy}\")\n",
        "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "metadata": {
        "id": "BfiPQFHNrKqg",
        "outputId": "96111faa-4383-44fd-ef22-1cb8fce6a536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.9629629629629629\n",
            "F1 Score (Micro) = 0.9629629629629629\n",
            "F1 Score (Macro) = 0.9624278449697636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-9\"></a>\n",
        "# <span>9. Sauvegarde du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "khJH34-Y6eOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': BERTClass(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "metadata": {
        "id": "txBBhkjlIBKj",
        "outputId": "70294d44-1765-42b6-d338-1585d400a88d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-10\"></a>\n",
        "# <span>10. Test du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "2EFx0psm6kmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    \n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "GLnlh8IBFxWX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model = load_checkpoint('checkpoint.pth')"
      ],
      "metadata": {
        "id": "gQt65jD-mB-L"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = \"hello there\"\n",
        "\n",
        "d = {'data': [news]}\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "test_set = CustomDataset(df, tokenizer, MAX_LEN, is_target = False)"
      ],
      "metadata": {
        "id": "NPga-nfiKE9d"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_params = {'batch_size': 1,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "_loader = DataLoader(test_set, **_params)"
      ],
      "metadata": {
        "id": "mGFwfI55SlsQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_model.eval()\n",
        "the_model.to(device)\n",
        "for _,data in enumerate(_loader, 0):\n",
        "  ids = data['ids'].to(device)\n",
        "  mask = data['mask'].to(device)\n",
        "  token_type_ids = data['token_type_ids'].to(device)\n",
        "  \n",
        "  outputs = the_model(ids, mask, token_type_ids)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "  print(predicted)"
      ],
      "metadata": {
        "id": "8k115lQfmQoe",
        "outputId": "c8b42c86-3274-42dc-b0b6-b75669605b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}