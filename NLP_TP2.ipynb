{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandsOnAI_2/blob/main/NLP_TP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data"
      ],
      "metadata": {
        "id": "9NBGroUDYfTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "w844LGUkpjC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installation de librairies**"
      ],
      "metadata": {
        "id": "CxSQeTSAx9nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "UL3K32_vyATT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=150, nanstr='nan', precision=3, suppress=False, threshold=1000, formatter=None)"
      ],
      "metadata": {
        "id": "Y1JcFys6t1QK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Chargement des bases de données**"
      ],
      "metadata": {
        "id": "b-Fj2VOarnz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Sklearn sur le jeu de données 20newsgroup\n",
        "\n",
        "Commençons par importer le jeu de données 20newsgroup (https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html). Ce jeu de données contient 18 000 news sur 20 thématiques différentes. Il est également divisé en deux sous-ensembles: le *training set*, pour entrainer un modèle, et le *test set* pour évaluer le modèle entrainé.\n",
        "\n",
        "Dans le bloc de code suivant, nous importons le *training set* (subset='train'). Nous précisons également que les données de cet ensemble doivent être mélangées (shuffle=True). La variable *random_state* permet de fixer la *seed* des opérations aléatoires, ce qui garantit d'obtenir le même résultat à chaque exécution."
      ],
      "metadata": {
        "id": "STxUq5bksF9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_ds_train = fetch_20newsgroups(subset='train', shuffle = True, random_state = 42)"
      ],
      "metadata": {
        "id": "sTVPXmYNvC3N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le bloc de code suivant, plusieurs éléments sont affichés :\n",
        "* La liste des topics abordés dans le jeu de données\n",
        "* Le nombre de news \n",
        "* Le contenu de la 1ère news\n",
        "* Le topic de la 1ère news"
      ],
      "metadata": {
        "id": "sLKHZqN1vI0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Liste des topics\")\n",
        "print(news_ds_train.target_names)\n",
        "print(\"\")\n",
        "print(\"Nombre de news\")\n",
        "print(len(news_ds_train.data))\n",
        "print(\"\")\n",
        "print(\"Affichage de la 1ère news\")\n",
        "print(news_ds_train.data[0])\n",
        "print(\"\")\n",
        "print(\"Topic de la 1ère news\")\n",
        "print(news_ds_train.target_names[news_ds_train.target[0]])"
      ],
      "metadata": {
        "id": "fzWrEwDbvnA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si nous ne souhaitons pas travailler avec tous les topics, il est possible de déterminer dès le chargement du jeu de données les catégories que l'on souhaite utiliser."
      ],
      "metadata": {
        "id": "aPwasbpRv3Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
        "news_ds_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "print(news_ds_train.target_names)"
      ],
      "metadata": {
        "id": "C0tDMwpkwH92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Huggingface sur le jeu de données 20newsgroup\n",
        "\n",
        "Le chargement du jeu de données avec Huggingface est très similaire à celui de sklearn, à quelques détails près. Le bloc de code suivant vous montre comment procéder avec Huggingface pour obtenir les mêmes résultats qu'avec sklearn."
      ],
      "metadata": {
        "id": "_j7z_05wxvVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "hugging_news_train = load_dataset('SetFit/20_newsgroups', split = 'train')\n",
        "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
        "hugging_news_train = hugging_news_train.filter(lambda row: row['label_text'] in categories)\n",
        "\n",
        "print(\"Nombre de news\")\n",
        "print(len(hugging_news_train))\n",
        "print(\"\")\n",
        "print(\"Affichage de la 1ère news\")\n",
        "print(hugging_news_train[0])\n",
        "print(\"\")\n",
        "print(\"Topic de la 1ère news\")\n",
        "print(hugging_news_train[0]['label_text'])"
      ],
      "metadata": {
        "id": "NFkAKMrL5F1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Classification de textes**"
      ],
      "metadata": {
        "id": "PWGDx4pc5ffa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Classification avec sklearn\n",
        "Dans cette section, nous allons entrainer un modèle pour classifier les news du jeu de données 20newsgroup avec la librairie sklearn.\n",
        "\n",
        "Dans le bloc de code suivant, commencez par importer le jeu de données comme nous l'avons vu au point 1.1. Conservez les topics suivants : \n",
        "* alt.atheism\n",
        "* comp.graphics\n",
        "* rec.motorcycles\n",
        "* sci.crypt\n",
        "* sci.med\n",
        "\n",
        "Ne mélangez pas les news du *test set*."
      ],
      "metadata": {
        "id": "06cE5KD76oA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sur base de ce que nous avons fait la semaine passée, comptez le nombre d'occurence des mots dans le corpus que nous venons de créer (ce corpus correspond à la variable *news_ds_train.data*).\n",
        "\n",
        "Vectorisez ensuite ce corpus avec TF-IDF. Enregistrez ces features du corpus dans la variable *corpus_X*."
      ],
      "metadata": {
        "id": "3w0pg7Ww8A8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'comp.graphics', 'rec.motorcycles', 'sci.crypt','sci.med']\n",
        "news_ds_train = fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = 42)\n",
        "print(news_ds_train.target_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "HdnT7qaS8Mbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons maintenant entrainer un modèle appelé *Multinomial Naive Bayes* sur ce corpus. Les labels du corpus se trouvent dans la variable *news_ds_train.target*."
      ],
      "metadata": {
        "id": "WurEGc0h9bNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf_sklearn = MultinomialNB().fit(corpus_X, news_ds_train.target)"
      ],
      "metadata": {
        "id": "5sqTNejE9u7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le bloc de code suivant, nous utilisons notre modèle entrainé sur des phrases pré-sélectionnées. Est-ce que votre modèle semble performant par rapport aux thématiques choisies ?"
      ],
      "metadata": {
        "id": "X7fgDcGc-R0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = ['Your post is based on the premise that the laws as they stand do not discriminate anybody', 'OpenGL on the GPU is fast']\n",
        "\n",
        "# Vectorisez avec TF-IDF ces phrases\n",
        "X_new_tfidf = ????????????????? # votre code ici\n",
        "\n",
        "predicted = clf_sklearn.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, news_ds_train.target_names[category]))"
      ],
      "metadata": {
        "id": "0A6Kjm-2-Yar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Classification avec les transformers de Huggingface"
      ],
      "metadata": {
        "id": "N9j06HpC_SSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette section, nous vous proposons d'entrainer un modèle pour classifier les news du jeu de données 20newsgroup avec la librairie transformer de Huggingface.\n",
        "\n",
        "Nous vous suggérons d'explorer l'utilisation de cette librairie sur base du lien suivant : https://huggingface.co/docs/transformers/tasks/sequence_classification "
      ],
      "metadata": {
        "id": "12gn4wbi_a70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Votre code ici"
      ],
      "metadata": {
        "id": "ONPAZoeimQv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Métriques de classification"
      ],
      "metadata": {
        "id": "YpsL7UP4MfN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Métriques de la classification avec sklearn\n",
        "\n",
        "Dans la section 2.1, nous avons entrainé un modèle de classification avec sklearn. Nous allons maintenant voir comment mesurer ses performances.\n",
        "\n",
        "Dans le bloc de code suivant, nous utilisons notre modèle sur le corpus d'entrainement afin de déterminer ses prédictions pour chaque news d'entrainement. Nous utilisons ensuite la fonction *classification_report* pour mesurer différentes métriques sur le modèle."
      ],
      "metadata": {
        "id": "47SmNfkWMjtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = clf_sklearn.predict(corpus_X)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(news_ds_train.target, predicted,\n",
        "    target_names=news_ds_train.target_names))\n"
      ],
      "metadata": {
        "id": "mP6zGb72Mxxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En pratique, pour comparer des modèles entrainés, nous les évaluons sur le *test set*. Evaluez le modèle entrainé avec sklearn sur notre test set."
      ],
      "metadata": {
        "id": "Ww1EP5piNzMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_test = vectorizer.transform(news_ds_test.data)\n",
        "\n",
        "predicted = clf_sklearn.predict(corpus_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(news_ds_test.target, predicted,\n",
        "    target_names=news_ds_test.target_names))"
      ],
      "metadata": {
        "id": "ngjNFhdbN-Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayez maintenant d'entrainer un modèle MLPClassifier de sklearn. Aidez-vous de la procédure complète de l'entrainement effectué pour sklearn et comparez votre modèle à celui entrainé précédement."
      ],
      "metadata": {
        "id": "i05CuLrcQf0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Chargez les datasets en conservant les mêmes catégories\n",
        "# Votre code ici\n",
        "\n",
        "# Utilisez TF-IDF pour convertir les données\n",
        "# Votre code ici\n",
        "\n",
        "# Initializez le MLPClassifier et entrainez-le\n",
        "# Votre code ici\n",
        "\n",
        "# Evaluez le modèle sur le training set\n",
        "# Votre code ici\n",
        "\n",
        "# Evaluez le modèle sur le test set\n",
        "# Votre code ici"
      ],
      "metadata": {
        "id": "_Ev8h20WQszW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Modèles de langage"
      ],
      "metadata": {
        "id": "eRIPCS8JSQP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette section, nous allons travailler avec les modèles de langage et voir différentes tâches sur lesquelles ils peuvent être utilisées."
      ],
      "metadata": {
        "id": "lc7l9QzKSThn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ce bloc charge des librairies qui seront utilisées dans la suite de cette section\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jqL3w26mSl_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Prédire la suite d'une phrase\n",
        "\n",
        "Un modèle de language peut être utilisé pour prédire le prochain mot d'une phrase. Pour ce faire nous utiliserons l'identifiant 'distilgpt2' et des modèles basés sur GPT-2 (voir bloc de code ci-dessous)."
      ],
      "metadata": {
        "id": "TwbS8bUdaNYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'distilgpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "gCt4rOooSodn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le bloc de code suivant vous montre comment utiliser ces modèles pour générer la suite d'une phrase. Essayez différentes phrases et différents nombres de mots à générer. \n",
        "\n",
        "En cherchant en ligne les différentes fonctions utilisées dans ce bout de code, essayez de comprendre ce qui y est fait."
      ],
      "metadata": {
        "id": "NGOY8-4oajup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The human reads a\"\n",
        "encodings = tokenizer(sentence, return_tensors='pt')\n",
        "print(encodings)\n",
        "\n",
        "words_to_generate = 5 # Nombre de mots à générer à la suite de la phrase d'exemple\n",
        "\n",
        "for i in tqdm(range(words_to_generate)):\n",
        "  with torch.no_grad():\n",
        "    encodings.input_ids = encodings.input_ids\n",
        "    output = model(encodings.input_ids).logits[:, -1, :]\n",
        "    # filter\n",
        "    filtered_next_token_logits = top_k_top_p_filtering(output, top_k=50, top_p=1.0)\n",
        "\n",
        "    # sample\n",
        "    probs = nn.functional.softmax(filtered_next_token_logits, dim=-1)\n",
        "    next_token = torch.multinomial(probs, num_samples=1)\n",
        "    encodings.input_ids = torch.cat((encodings.input_ids, next_token), dim=-1)\n",
        "    encodings.attention_mask = torch.cat((encodings.attention_mask, torch.tensor([[1]])), dim=-1)\n",
        "\n",
        "\n",
        "resulting_string = tokenizer.decode(encodings.input_ids.tolist()[0])\n",
        "print(resulting_string)"
      ],
      "metadata": {
        "id": "6hMqg23vSyxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Fill-mask\n",
        "\n",
        "Dans cette tâche, un mot de la phrase est manquante (marquée par le token [MASK]). Un modèle de langage peut être utilisé pour calculer le mot le plus probable de la phrase."
      ],
      "metadata": {
        "id": "61QByxvKb0JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "lm_unmasker = pipeline('fill-mask', model='distilbert-base-uncased')\n",
        "lm_unmasker(\"The human reads a [MASK]\")"
      ],
      "metadata": {
        "id": "8cScT9NRUkh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le mot manquant ne doit pas toujours être situé en fin de phrase :"
      ],
      "metadata": {
        "id": "GJ3buFzDci7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_unmasker(\"Paris is the [MASK] of France.\")"
      ],
      "metadata": {
        "id": "CscG6hJWV9Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inventez vous-mêmes quelques phrases, remplacez un mot dans celles-ci par le token [MASK]. Le modèle a-t-il retrouvé ce que vous aviez mis initialement ?"
      ],
      "metadata": {
        "id": "5TGz06V1ctaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Votre code ici"
      ],
      "metadata": {
        "id": "UDD5BxSqc3Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Perplexité\n",
        "\n",
        "La perplexité d'un modèle du langage est inversément proportionnelle à la qualité de ce modèle. Une valeur de 1 (au plus petit, au mieux c'est) serait obtenue avec un modèle parfait. Une perplexité de 30 (à titre d'exemple) serait obtenu avec un modèle plutôt hésitant.\n",
        "\n",
        "Le bout de code charge une portion d'une variante du jeu de données 20 newsgroup. Le code qui suit vous montre comment calculer la perplexité de notre modèle du langage."
      ],
      "metadata": {
        "id": "q1Ke41IGYbw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = load_dataset('newsgroup', 'bydate_alt.atheism', split='test')\n",
        "print('\\n\\n'.join(test['text']))\n",
        "encodings = tokenizer('\\n\\n'.join(test['text'][:10]), return_tensors='pt')\n",
        "print(encodings.input_ids.shape)"
      ],
      "metadata": {
        "id": "hwFWyGM6Yc1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 256\n",
        "stride = 512\n",
        "\n",
        "nlls = []\n",
        "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
        "    begin_loc = max(i + stride - context_length, 0)\n",
        "    end_loc = min(i + stride, encodings.input_ids.size(1))\n",
        "    if end_loc <= begin_loc:\n",
        "      break\n",
        "\n",
        "    trg_len = end_loc - i    # may be different from stride on last loop\n",
        "    input_ids = encodings.input_ids[:,begin_loc:end_loc]\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:,:-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "    nlls.append(neg_log_likelihood)\n",
        "\n",
        "ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
        "print(ppl)"
      ],
      "metadata": {
        "id": "3AC8ygOrYjPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Data Augmentation"
      ],
      "metadata": {
        "id": "vqrl7i51dbtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Augmentation de données avec word2vec\n",
        "\n",
        "Le bout de code suivant prépare le modèle word2vec pour vous."
      ],
      "metadata": {
        "id": "cCuJa3xcdeo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gensim\n",
        "from gensim import downloader\n",
        "# Model loading\n",
        "if os.path.isdir(\"gensim-data\"):\n",
        "  from gensim.models import KeyedVectors\n",
        "  glove_model_en = KeyedVectors.load_word2vec_format(os.path.join('gensim-data', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-50.gz'))\n",
        "else:\n",
        "  glove_model_en = downloader.load(\"glove-wiki-gigaword-50\")\n",
        "  os.system('cp -R /root/gensim-data ./gensim-data')\n",
        "\n",
        "print(\"Loaded vocab size %i\" % len(glove_model_en.vocab.keys()))\n",
        "\n",
        "model = glove_model_en"
      ],
      "metadata": {
        "id": "VHVqTruDdhjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le script suivant permet de remplacer les mots d'une phrase par les mots les plus similaires à ceux-ci. Observez le résultat. Quels sont les problèmes que l'on rencontre ?"
      ],
      "metadata": {
        "id": "lmbdPJSUdxKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The boy is running on the field\"\n",
        "augmented_sentence = []\n",
        "for w in sentence.lower().split(\" \"):\n",
        "  augmented_sentence.append(model.most_similar(w)[0][0])\n",
        "\n",
        "augmented_sentence = ' '.join(augmented_sentence)\n",
        "print(augmented_sentence)"
      ],
      "metadata": {
        "id": "ykE8eplDd3Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une solution à ces problèmes est de ne remplacer que certains mots (les noms ou les verbes). Utilisez la librairie spacy (cfr. séance précédente) pour remplacer chaque nom de la phrase par son mot le plus similaire.\n",
        "\n",
        "Par facilité, nous ne tiendrons pas compte des ponctuations."
      ],
      "metadata": {
        "id": "lImTV3HfdiHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# votre code ici"
      ],
      "metadata": {
        "id": "MELjI9SMeCQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faites-en de même, mais en remplaçant les verbes !"
      ],
      "metadata": {
        "id": "Tvqbq3U-gCkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# votre code ici"
      ],
      "metadata": {
        "id": "11W0XqAVgGYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelles obsevations peut-on faire ?\n",
        "\n",
        "*Votre réponse ici*"
      ],
      "metadata": {
        "id": "6MDq_gq0gNCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Augmentation de données avec WordNet\n",
        "\n",
        "WordNet permet de trouver les mots synonymes d'un autre mot. Dans le code suivant, nous vous proposons une fonction utilisant WordNet pour trouver une liste de synonymes pour un mot donné."
      ],
      "metadata": {
        "id": "_y9i8A6NgdTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from collections import OrderedDict\n",
        "from nltk.tokenize import word_tokenize\n",
        "def find_synonyms(word):\n",
        "  synonyms = []\n",
        "  for synset in wordnet.synsets(word):\n",
        "    for syn in synset.lemma_names():\n",
        "      synonyms.append(syn)\n",
        "\n",
        "  # using this to drop duplicates while maintaining word order (closest synonyms comes first)\n",
        "  synonyms_without_duplicates = list(OrderedDict.fromkeys(synonyms))\n",
        "  synonyms_without_duplicates.remove(word) # remove the word if it's in the list\n",
        "  return synonyms_without_duplicates"
      ],
      "metadata": {
        "id": "y_9HgfB_gygO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons vérifier cette fonction avec le code suivant"
      ],
      "metadata": {
        "id": "4y1cit-Bg5io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms = find_synonyms(\"boy\")\n",
        "print(synonyms)"
      ],
      "metadata": {
        "id": "jJprp5UHg8sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposez maintenant un script similaire à ceux utilisés dans la Section 5.1 en utilisant WordNet pour remplacer les noms de la phrase par un synonyme."
      ],
      "metadata": {
        "id": "iY13IOpRhHm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# votre code ici"
      ],
      "metadata": {
        "id": "9gVOMJwWhVN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelles obsevations peut-on faire ?\n",
        "\n",
        "*Votre réponse ici*"
      ],
      "metadata": {
        "id": "_OWPO0_Lk6Im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3. Augmentation de données avec un modèle de language\n",
        "\n",
        "En remplaçant les noms d'une phrase par le token [MASK], nous pouvons utiliser la tâche fill-mask et un modèle du langage (section 4.2) pour trouver des idées pour créer de nouvelles phrases.\n",
        "\n",
        "Implémentez cette idée dans le bloc de code suivant."
      ],
      "metadata": {
        "id": "bs55hBYVhozH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# votre code ici"
      ],
      "metadata": {
        "id": "Fkyr09_ciP5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelles obsevations peut-on faire ?\n",
        "\n",
        "*Votre réponse ici*"
      ],
      "metadata": {
        "id": "6bbBeiX5k7W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4. Autres méthodes d'augmentation de données pour le NLP\n",
        "\n",
        "D'autres approches sont possibles pour augmenter les données dans une tâche de NLP. Nous vous invitons à consulter les documents suivants et de tenter d'expérimenter par vous-mêmes.\n",
        "\n",
        "* https://neptune.ai/blog/data-augmentation-nlp\n",
        "* https://github.com/makcedward/nlpaug"
      ],
      "metadata": {
        "id": "qPBBSJ-lk86a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vos expérimentations ici"
      ],
      "metadata": {
        "id": "bK_D3ZlDlrTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}