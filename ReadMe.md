# **Session 1** : Extraction de features

- Word Vectors
    - One-hot encoding
    - Lexical databases (WordNet)
    - Word embeddings (Word2vec)

- From Word to Text Vectors
    - Term frequency (TF)
    - Inverse document frequency (IDF)
    - Variants : TF-IDF, TF-PDF, TF, IDuF
    - Doc2vec

- Tools
    - Scikit-learn : TF, TF-IDF (sparse)
    - Transformers (huggingFace) : embedding (dense contextuel)
    - Gensim : word2vec (dense non-contextuel)
    - SpaCy : POS, NER (symbolique)

# **Session 2**

- Dimensionality Reduction
    - PCA
    - t-SNE
    - UMAP
    - TriMAP
    - https://scikit-learn.org/stable/modules/unsupervised_reduction.html

- Language Modeling
    - CNN
    - RNN
    - n-gram
    - LSTM
    - LSTM + attention
    - DNN + attention = Transformers

- Evaluating Language Modeling
    - Perplexity
    - BLEU
    - ROUGE
    - METEOR

- Dataset Scrapping/Crawling
    - https://scrapy.org/
    - https://github.com/gbolmier/newspaper-crawler
    - https://github.com/jeugregg/FakeNewsDetectionFr

- Data Annotation
    - http://jkk.name/slate/
    - https://aclanthology.org/P19-3002.pdf

- Data Augmentation
    - EDA : https://github.com/jasonwei20/eda_nlp
    - Albumentaitons : https://github.com/albumentations-team/albumentations
    - NLPAug : https://github.com/makcedward/nlpaug
    - Translation system into translation system
    - https://neptune.ai/blog/data-augmentation-nlp

- More ressources 
    - https://web.stanford.edu/~jurafsky/
    - https://nlp.stanford.edu
    - https://nlp.stanford.edu/manning/

