{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/ValentinCord/HandsOnAI_2/blob/main/NLP_Transformer.ipynb",
      "authorship_tag": "ABX9TyPpu/KZKnM2+Dqf/5LzEbGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandsOnAI_2/blob/main/Transformer_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span> NLP : Entrainnement et sauvegarde du modèle </span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "ye36lI82y9VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Installations](#section-1)\n",
        "* [Imports](#section-2)\n",
        "* [Choix des paramètres](#section-3)\n",
        "* [Lecture des données](#section-4)\n",
        "* [Preprocessing](#section-5)\n",
        "* [Création du modèle](#section-6)\n",
        "* [Entrainement du modèle](#section-7)\n",
        "* [Prédiction des données](#section-8)\n",
        "* [Sauvegarde du modèle](#section-9)\n",
        "* [Test du modèle](#section-10)"
      ],
      "metadata": {
        "id": "r3b3mz3VzLwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-1\"></a>\n",
        "# <span>1. Installation des packages</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "76dtzVzXzQ8h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndfJjNRbOtqA",
        "outputId": "8e1ea20d-21dd-4125-b6f3-bf50115ff2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 28 10:51:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    31W /  70W |   6898MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data\n",
        "\n",
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-2\"></a>\n",
        "# <span>2. Imports </span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "KESAm8EZyjNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basics \n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# transformers \n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# plot \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "# torch \n",
        "import torch\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# nltk \n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "IItKtGo1O8yQ",
        "outputId": "2c2fd8d3-9136-4c96-a5fd-c4bc70a19f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "fGXyKBKhQAVX",
        "outputId": "8d2501db-83c4-4766-9c49-82b02263f631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section-3\"></a>\n",
        "# <span>3. Choix des paramètres</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "\n",
        "<p align=\"justify\">Dans cette section, nous pouvons paramétrer les données d'entrée et les données de notre modèle. Pour les paramètres du modèle, nous pouvons définir : le batch size, le nombre d'epochs ainsi que le learning rate.</p>\n",
        "\n",
        "<p align=\"justify\">Pour la préparation des données, il faut savoir que les Transformers acceptent uniquement les données d'une taille bien. définie. Dans le cas de notre Transformer, celle-ci est de 512. Il est possible que nous ayons des News de trop grandes taille. Au lieu de tronquer les données et risquer de perdre de l'information, nous avons décidé de splitter les News. Il nous est donc possible définir la taille maximum des morceaux de News et de leur overlap.</p>"
      ],
      "metadata": {
        "id": "2-QTduv_z_sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 10\n",
        "VALID_BATCH_SIZE = 10\n",
        "EPOCHS =5\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "LEN_TEXT = 150\n",
        "OVERLAP = 50\n",
        "\n",
        "DONNEE_AJOUTEES = 500\n",
        "\n",
        "TRANSFORMER_NAME = \"cmarkea/distilcamembert-base\"\n",
        "TRAIN_SIZE = 0.8"
      ],
      "metadata": {
        "id": "Wxi7T3Aa0mVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-4\"></a>\n",
        "# <span>4. Lecture des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "quksqXzGSHdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_train.csv'\n",
        "added_path = '/content/drive/MyDrive/HandOnAI_2_NLP/added_train.csv'\n",
        "test_path = '/content/drive/MyDrive/HandOnAI_2_NLP/fake_test.csv'\n",
        "\n",
        "df = pd.read_csv(train_path)\n",
        "df_added = pd.read_csv(added_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# suppression des colonnes inutiles \n",
        "df = df.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "df_added.rename(columns = {'french':'data'}, inplace = True)\n",
        "df_added = df_added.drop(['Unnamed: 0'], axis = 1)\n",
        "df_test = df_test.drop(['Unnamed: 0', 'target_name'], axis = 1)\n",
        "\n",
        "df = df.append(df_added[:DONNEE_AJOUTEES], ignore_index=True)"
      ],
      "metadata": {
        "id": "tiOqzZa_QBHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-5\"></a>\n",
        "# <span>5. Preprocessing</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p align=\"justify\">La partie preprocessing peut être scindée en plusieurs étapes. En premier, nous allons appliquer un nettoyage de données. Suite à ce nettoyage, les données seront converties dans le format adéquat. </p>\n",
        "\n"
      ],
      "metadata": {
        "id": "lHZiX4aQ1ArO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.1 Nettoyage de données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "\n",
        "1.   Suppression des stopwords : les stopwords sont des mots qui n'apportent pas d'informations supplémentaires au texte. Afin de réduire la taille des news, on pourrait effectuer la suppression de ceux-ci.\n",
        "2.   Suppression des caractères spéciaux : en regardant plusieurs news, nous avons constaté qu'il y avait plusieurs caractères spéciaux. N'apportant aucune information supplémentaire, nous pouvons les supprimer. "
      ],
      "metadata": {
        "id": "jjRFdSHk29uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('french'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    #text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "metadata": {
        "id": "jb8g1SRXMV6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data'] = df['data'].apply(clean_text)\n",
        "df_test['data'] = df_test['data'].apply(clean_text)\n",
        "\n",
        "df = df.drop(df.index[1430])\n",
        "df = df.drop(df.index[1429])\n",
        "df = df.drop(df.index[1180])\n",
        "df = df.drop(df.index[1136])\n",
        "df = df.reset_index()"
      ],
      "metadata": {
        "id": "MFuS0cn_NznG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.2 Découpage des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "\n",
        "<p align=\"justify\">Comme expliqué dans le choix des paramètres, nous allons ici couper les News en plusieurs morceaux à l'aide de la fonction get_split. La fonction est ensuite appliquée aussi bien sur le jeu de données d'entrainement et de test.</p>"
      ],
      "metadata": {
        "id": "Txki6c5y3oYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//(LEN_TEXT - OVERLAP) >0:\n",
        "        n = len(text1.split())//(LEN_TEXT - OVERLAP)\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*(LEN_TEXT - OVERLAP):w*(LEN_TEXT - OVERLAP) + LEN_TEXT]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total"
      ],
      "metadata": {
        "id": "CsSspiWDNQ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_split'] = df['data'].apply(get_split)\n",
        "df['len_split'] = df['text_split'].apply(lambda x: len(x))\n",
        "\n",
        "df_test['text_split'] = df_test['data'].apply(get_split)\n",
        "df_test['len_split'] = df_test['text_split'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "zPkVbv9gNSh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "  if len(row['text_split']) > 1: \n",
        "    print(index)\n",
        "    break\n",
        "\n",
        "print(df['text_split'][31][0].split()[(LEN_TEXT - OVERLAP):])\n",
        "print(df['text_split'][31][1].split()[:OVERLAP])"
      ],
      "metadata": {
        "id": "6UFYbVkZw-5x",
        "outputId": "9c9ab28b-4c23-4f0c-f546-f755b5e3ab8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "['walter', 'luis', 'alvarez', 'avancé', \"l'\", 'extinction', 'massive', 'fin', 'crétacé', 'spectaculairement', 'manifestée', 'disparition', 'dinosaures', 'provenait', 'chute', \"d'un\", 'astéroïde', '.', 'selon', 'cette', 'théorie', \"l'impact\", \"d'un\", 'petit', 'corps', 'céleste', \"d'environ\", '10', 'km', 'diamètre', 'perturbé', 'biosphère', 'multiples', 'façons', 'notamment', 'éjectant', 'tellement', 'matériaux', \"l'\", 'atmosphère', \"l'ensoleillement\", 'chuté', 'considérablement', 'provoquant', 'mort', 'végétaux', 'nombreuses', 'espèces', 'animales', 'entraînés']\n",
            "['walter', 'luis', 'alvarez', 'avancé', \"l'\", 'extinction', 'massive', 'fin', 'crétacé', 'spectaculairement', 'manifestée', 'disparition', 'dinosaures', 'provenait', 'chute', \"d'un\", 'astéroïde', '.', 'selon', 'cette', 'théorie', \"l'impact\", \"d'un\", 'petit', 'corps', 'céleste', \"d'environ\", '10', 'km', 'diamètre', 'perturbé', 'biosphère', 'multiples', 'façons', 'notamment', 'éjectant', 'tellement', 'matériaux', \"l'\", 'atmosphère', \"l'ensoleillement\", 'chuté', 'considérablement', 'provoquant', 'mort', 'végétaux', 'nombreuses', 'espèces', 'animales', 'entraînés']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.3 Reformulation du labels</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p align=\"justify\"> Dans cette partie, le label est reformulé sous la forme OneHot.</p>"
      ],
      "metadata": {
        "id": "8Lr3VKvG4e_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(df): \n",
        "  train_l = []\n",
        "  label_l = []\n",
        "  for idx,row in df.iterrows():\n",
        "      for l in row['text_split']:\n",
        "          train_l.append(l)\n",
        "          label_l.append([1 if row['label'] == i else 0 for i in range(2)])\n",
        "\n",
        "  return pd.DataFrame({'data':train_l, 'label':label_l})"
      ],
      "metadata": {
        "id": "X0tOshbBOtdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = create_df(df)\n",
        "cleaned_df_test = create_df(df_test)"
      ],
      "metadata": {
        "id": "c3Ef_wbQO2DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.4 Création du dataset</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p align=\"justify\">La création de la classe CustomDataset permet de reformuler les données dans le format souhaité. Comme nous utilisons un Transformer, nous devons :</p>\n",
        "\n",
        "1.   Utiliser un tokenizer\n",
        "2.   Récupérer le \"token id\" et le \"attention mask\""
      ],
      "metadata": {
        "id": "fUwS-dIw4ssX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len, is_target = True):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = dataframe\n",
        "        self.text = dataframe.data\n",
        "        self.max_len = max_len\n",
        "        if is_target: \n",
        "          self.targets = self.df.label\n",
        "        else: \n",
        "          self.targets = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        if self.targets is None: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "          }\n",
        "        else: \n",
        "          return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(mask, dtype=torch.long),\n",
        "              'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "          }"
      ],
      "metadata": {
        "id": "B1zIS8_5f1km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_NAME)\n",
        "\n",
        "train_dataset = cleaned_df.sample(frac=TRAIN_SIZE,random_state=200)\n",
        "test_dataset = cleaned_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(cleaned_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(cleaned_df, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(cleaned_df_test, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "unfGKfEHg0Ir",
        "outputId": "926df926-8520-4f77-cf44-e61cba4e4c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (4685, 2)\n",
            "TRAIN Dataset: (3748, 2)\n",
            "TEST Dataset: (937, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span>5.5 Création du dataloader</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "klqYDdm45g5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "FkinDs9Mj42G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-6\"></a>\n",
        "# <span>6. Création du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p align=\"justify\">Afin de pouvoir configurer au maximum le modèle, nous avons voulu créer une classe pour le modèle. Dans cette classe, nous pouvons définir les différentes couches. Une fois le modèle définit, nous pouvons définir la fonction loss ainsi que la fonction d'entrainement.</p>"
      ],
      "metadata": {
        "id": "XZMYZMWE5wcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "      super(BERTClass, self).__init__()\n",
        "      self.l1 = CamembertModel.from_pretrained(TRANSFORMER_NAME)\n",
        "      self.l3 = torch.nn.Linear(768, 2) #2 = binary classification\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      output = self.l3(output_1['pooler_output'])\n",
        "\n",
        "      return F.softmax(output, dim=1)\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "YI-RQetem1Ou",
        "outputId": "1b7f1396-85ae-4ebe-fb0a-6f4f090c9986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l3): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "cHuUpT28bBFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device)\n",
        "        mask = data['mask'].to(device)\n",
        "        token_type_ids = data['token_type_ids'].to(device)\n",
        "        targets = data['targets'].to(device)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%10==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GkLpQpkrcXj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-7\"></a>\n",
        "# <span>7. Entrainement du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "QgHnsZNE6D_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "V1oQxlezm-qh",
        "outputId": "55244c5a-c0d4-4a73-825a-008317d03927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.6840534210205078\n",
            "Epoch: 0, Loss:  0.6824912428855896\n",
            "Epoch: 0, Loss:  0.6125276684761047\n",
            "Epoch: 0, Loss:  0.6017783880233765\n",
            "Epoch: 0, Loss:  0.6104455590248108\n",
            "Epoch: 0, Loss:  0.5176016688346863\n",
            "Epoch: 0, Loss:  0.6925471425056458\n",
            "Epoch: 0, Loss:  0.600463330745697\n",
            "Epoch: 0, Loss:  0.6949084401130676\n",
            "Epoch: 0, Loss:  0.4859329164028168\n",
            "Epoch: 0, Loss:  0.5126347541809082\n",
            "Epoch: 0, Loss:  0.45529890060424805\n",
            "Epoch: 0, Loss:  0.5158266425132751\n",
            "Epoch: 0, Loss:  0.42135557532310486\n",
            "Epoch: 0, Loss:  0.39204248785972595\n",
            "Epoch: 0, Loss:  0.516261875629425\n",
            "Epoch: 0, Loss:  0.3835049271583557\n",
            "Epoch: 0, Loss:  0.4217202663421631\n",
            "Epoch: 0, Loss:  0.47700071334838867\n",
            "Epoch: 0, Loss:  0.6411043405532837\n",
            "Epoch: 0, Loss:  0.6244808435440063\n",
            "Epoch: 0, Loss:  0.3397986888885498\n",
            "Epoch: 0, Loss:  0.4502750039100647\n",
            "Epoch: 0, Loss:  0.6843103766441345\n",
            "Epoch: 0, Loss:  0.46425411105155945\n",
            "Epoch: 0, Loss:  0.4534526765346527\n",
            "Epoch: 0, Loss:  0.31999117136001587\n",
            "Epoch: 0, Loss:  0.6442949175834656\n",
            "Epoch: 0, Loss:  0.4642091393470764\n",
            "Epoch: 0, Loss:  0.583350419998169\n",
            "Epoch: 0, Loss:  0.33803102374076843\n",
            "Epoch: 0, Loss:  0.6114368438720703\n",
            "Epoch: 0, Loss:  0.47977495193481445\n",
            "Epoch: 0, Loss:  0.6428744792938232\n",
            "Epoch: 0, Loss:  0.32790079712867737\n",
            "Epoch: 0, Loss:  0.3825328052043915\n",
            "Epoch: 0, Loss:  0.3276248872280121\n",
            "Epoch: 0, Loss:  0.32161155343055725\n",
            "Epoch: 0, Loss:  0.37435150146484375\n",
            "Epoch: 0, Loss:  0.38494130969047546\n",
            "Epoch: 0, Loss:  0.5145697593688965\n",
            "Epoch: 0, Loss:  0.3381410539150238\n",
            "Epoch: 0, Loss:  0.3656086325645447\n",
            "Epoch: 0, Loss:  0.50869220495224\n",
            "Epoch: 0, Loss:  0.5425041317939758\n",
            "Epoch: 0, Loss:  0.31693851947784424\n",
            "Epoch: 0, Loss:  0.511168897151947\n",
            "Epoch: 1, Loss:  0.32842954993247986\n",
            "Epoch: 1, Loss:  0.40874359011650085\n",
            "Epoch: 1, Loss:  0.5184235572814941\n",
            "Epoch: 1, Loss:  0.4048384726047516\n",
            "Epoch: 1, Loss:  0.5044057965278625\n",
            "Epoch: 1, Loss:  0.5173913836479187\n",
            "Epoch: 1, Loss:  0.465383380651474\n",
            "Epoch: 1, Loss:  0.3373239040374756\n",
            "Epoch: 1, Loss:  0.48187071084976196\n",
            "Epoch: 1, Loss:  0.4822750985622406\n",
            "Epoch: 1, Loss:  0.4267347455024719\n",
            "Epoch: 1, Loss:  0.34092050790786743\n",
            "Epoch: 1, Loss:  0.4486461281776428\n",
            "Epoch: 1, Loss:  0.413273423910141\n",
            "Epoch: 1, Loss:  0.33123132586479187\n",
            "Epoch: 1, Loss:  0.41065746545791626\n",
            "Epoch: 1, Loss:  0.47722578048706055\n",
            "Epoch: 1, Loss:  0.31756410002708435\n",
            "Epoch: 1, Loss:  0.42265066504478455\n",
            "Epoch: 1, Loss:  0.41269633173942566\n",
            "Epoch: 1, Loss:  0.45859986543655396\n",
            "Epoch: 1, Loss:  0.32788655161857605\n",
            "Epoch: 1, Loss:  0.34730395674705505\n",
            "Epoch: 1, Loss:  0.4431384205818176\n",
            "Epoch: 1, Loss:  0.3676113784313202\n",
            "Epoch: 1, Loss:  0.3153420388698578\n",
            "Epoch: 1, Loss:  0.4209827482700348\n",
            "Epoch: 1, Loss:  0.4198998510837555\n",
            "Epoch: 1, Loss:  0.4209778904914856\n",
            "Epoch: 1, Loss:  0.3141873776912689\n",
            "Epoch: 1, Loss:  0.3193046748638153\n",
            "Epoch: 1, Loss:  0.4179215431213379\n",
            "Epoch: 1, Loss:  0.460628479719162\n",
            "Epoch: 1, Loss:  0.38731905817985535\n",
            "Epoch: 1, Loss:  0.463358610868454\n",
            "Epoch: 1, Loss:  0.3202415406703949\n",
            "Epoch: 1, Loss:  0.40917420387268066\n",
            "Epoch: 1, Loss:  0.599853515625\n",
            "Epoch: 1, Loss:  0.3774172365665436\n",
            "Epoch: 1, Loss:  0.6632831692695618\n",
            "Epoch: 1, Loss:  0.4129396378993988\n",
            "Epoch: 1, Loss:  0.44628071784973145\n",
            "Epoch: 1, Loss:  0.3138231039047241\n",
            "Epoch: 1, Loss:  0.33474305272102356\n",
            "Epoch: 1, Loss:  0.4121113717556\n",
            "Epoch: 1, Loss:  0.31714165210723877\n",
            "Epoch: 1, Loss:  0.41461774706840515\n",
            "Epoch: 2, Loss:  0.6049968600273132\n",
            "Epoch: 2, Loss:  0.5569076538085938\n",
            "Epoch: 2, Loss:  0.43036705255508423\n",
            "Epoch: 2, Loss:  0.3139825761318207\n",
            "Epoch: 2, Loss:  0.3156678378582001\n",
            "Epoch: 2, Loss:  0.3256114721298218\n",
            "Epoch: 2, Loss:  0.3277429938316345\n",
            "Epoch: 2, Loss:  0.3145013749599457\n",
            "Epoch: 2, Loss:  0.399606317281723\n",
            "Epoch: 2, Loss:  0.5378912091255188\n",
            "Epoch: 2, Loss:  0.4503715932369232\n",
            "Epoch: 2, Loss:  0.315521776676178\n",
            "Epoch: 2, Loss:  0.31655555963516235\n",
            "Epoch: 2, Loss:  0.32297152280807495\n",
            "Epoch: 2, Loss:  0.3512660264968872\n",
            "Epoch: 2, Loss:  0.4450237452983856\n",
            "Epoch: 2, Loss:  0.4094458520412445\n",
            "Epoch: 2, Loss:  0.411895751953125\n",
            "Epoch: 2, Loss:  0.3249225616455078\n",
            "Epoch: 2, Loss:  0.342904657125473\n",
            "Epoch: 2, Loss:  0.4120675027370453\n",
            "Epoch: 2, Loss:  0.31489938497543335\n",
            "Epoch: 2, Loss:  0.3182724416255951\n",
            "Epoch: 2, Loss:  0.3136313855648041\n",
            "Epoch: 2, Loss:  0.31821510195732117\n",
            "Epoch: 2, Loss:  0.4138871133327484\n",
            "Epoch: 2, Loss:  0.31682953238487244\n",
            "Epoch: 2, Loss:  0.31647148728370667\n",
            "Epoch: 2, Loss:  0.3834170401096344\n",
            "Epoch: 2, Loss:  0.4134025573730469\n",
            "Epoch: 2, Loss:  0.40630242228507996\n",
            "Epoch: 2, Loss:  0.46754923462867737\n",
            "Epoch: 2, Loss:  0.3147490918636322\n",
            "Epoch: 2, Loss:  0.33343639969825745\n",
            "Epoch: 2, Loss:  0.40284252166748047\n",
            "Epoch: 2, Loss:  0.3544265329837799\n",
            "Epoch: 2, Loss:  0.31493327021598816\n",
            "Epoch: 2, Loss:  0.31372490525245667\n",
            "Epoch: 2, Loss:  0.33592256903648376\n",
            "Epoch: 2, Loss:  0.31999263167381287\n",
            "Epoch: 2, Loss:  0.4082593023777008\n",
            "Epoch: 2, Loss:  0.31875061988830566\n",
            "Epoch: 2, Loss:  0.4360269606113434\n",
            "Epoch: 2, Loss:  0.41627755761146545\n",
            "Epoch: 2, Loss:  0.3141601085662842\n",
            "Epoch: 2, Loss:  0.5120218396186829\n",
            "Epoch: 2, Loss:  0.3153667449951172\n",
            "Epoch: 3, Loss:  0.3173960745334625\n",
            "Epoch: 3, Loss:  0.31418806314468384\n",
            "Epoch: 3, Loss:  0.31388208270072937\n",
            "Epoch: 3, Loss:  0.33382493257522583\n",
            "Epoch: 3, Loss:  0.31347593665122986\n",
            "Epoch: 3, Loss:  0.42479845881462097\n",
            "Epoch: 3, Loss:  0.3168856203556061\n",
            "Epoch: 3, Loss:  0.3161264955997467\n",
            "Epoch: 3, Loss:  0.31391850113868713\n",
            "Epoch: 3, Loss:  0.32413020730018616\n",
            "Epoch: 3, Loss:  0.31411921977996826\n",
            "Epoch: 3, Loss:  0.3137877881526947\n",
            "Epoch: 3, Loss:  0.41355252265930176\n",
            "Epoch: 3, Loss:  0.3147278428077698\n",
            "Epoch: 3, Loss:  0.4013240933418274\n",
            "Epoch: 3, Loss:  0.31480643153190613\n",
            "Epoch: 3, Loss:  0.31649962067604065\n",
            "Epoch: 3, Loss:  0.3143865764141083\n",
            "Epoch: 3, Loss:  0.31415364146232605\n",
            "Epoch: 3, Loss:  0.41421160101890564\n",
            "Epoch: 3, Loss:  0.3162587285041809\n",
            "Epoch: 3, Loss:  0.5032740831375122\n",
            "Epoch: 3, Loss:  0.31392407417297363\n",
            "Epoch: 3, Loss:  0.3135576546192169\n",
            "Epoch: 3, Loss:  0.4820846617221832\n",
            "Epoch: 3, Loss:  0.4136427342891693\n",
            "Epoch: 3, Loss:  0.3134099245071411\n",
            "Epoch: 3, Loss:  0.40302038192749023\n",
            "Epoch: 3, Loss:  0.31712254881858826\n",
            "Epoch: 3, Loss:  0.31354889273643494\n",
            "Epoch: 3, Loss:  0.3136630058288574\n",
            "Epoch: 3, Loss:  0.31383123993873596\n",
            "Epoch: 3, Loss:  0.3139251470565796\n",
            "Epoch: 3, Loss:  0.31345000863075256\n",
            "Epoch: 3, Loss:  0.31807613372802734\n",
            "Epoch: 3, Loss:  0.40018001198768616\n",
            "Epoch: 3, Loss:  0.41346296668052673\n",
            "Epoch: 3, Loss:  0.31354615092277527\n",
            "Epoch: 3, Loss:  0.3335418701171875\n",
            "Epoch: 3, Loss:  0.32687798142433167\n",
            "Epoch: 3, Loss:  0.3137502372264862\n",
            "Epoch: 3, Loss:  0.4343843162059784\n",
            "Epoch: 3, Loss:  0.46303388476371765\n",
            "Epoch: 3, Loss:  0.31340405344963074\n",
            "Epoch: 3, Loss:  0.3165762424468994\n",
            "Epoch: 3, Loss:  0.405008465051651\n",
            "Epoch: 3, Loss:  0.3146456182003021\n",
            "Epoch: 4, Loss:  0.41193675994873047\n",
            "Epoch: 4, Loss:  0.3143787086009979\n",
            "Epoch: 4, Loss:  0.41310158371925354\n",
            "Epoch: 4, Loss:  0.3139004707336426\n",
            "Epoch: 4, Loss:  0.4154430329799652\n",
            "Epoch: 4, Loss:  0.31382378935813904\n",
            "Epoch: 4, Loss:  0.37018850445747375\n",
            "Epoch: 4, Loss:  0.3133751451969147\n",
            "Epoch: 4, Loss:  0.3134174346923828\n",
            "Epoch: 4, Loss:  0.3134322762489319\n",
            "Epoch: 4, Loss:  0.3524352014064789\n",
            "Epoch: 4, Loss:  0.31340381503105164\n",
            "Epoch: 4, Loss:  0.31363749504089355\n",
            "Epoch: 4, Loss:  0.3158065974712372\n",
            "Epoch: 4, Loss:  0.3148229718208313\n",
            "Epoch: 4, Loss:  0.3165145814418793\n",
            "Epoch: 4, Loss:  0.3134012818336487\n",
            "Epoch: 4, Loss:  0.3135388493537903\n",
            "Epoch: 4, Loss:  0.3134385943412781\n",
            "Epoch: 4, Loss:  0.31418684124946594\n",
            "Epoch: 4, Loss:  0.313513845205307\n",
            "Epoch: 4, Loss:  0.49264317750930786\n",
            "Epoch: 4, Loss:  0.4489459991455078\n",
            "Epoch: 4, Loss:  0.3133799135684967\n",
            "Epoch: 4, Loss:  0.31432977318763733\n",
            "Epoch: 4, Loss:  0.5110846757888794\n",
            "Epoch: 4, Loss:  0.3135204017162323\n",
            "Epoch: 4, Loss:  0.3804593086242676\n",
            "Epoch: 4, Loss:  0.3347724378108978\n",
            "Epoch: 4, Loss:  0.31336361169815063\n",
            "Epoch: 4, Loss:  0.3135235011577606\n",
            "Epoch: 4, Loss:  0.4513401687145233\n",
            "Epoch: 4, Loss:  0.313383549451828\n",
            "Epoch: 4, Loss:  0.4164491295814514\n",
            "Epoch: 4, Loss:  0.3133717477321625\n",
            "Epoch: 4, Loss:  0.3133609890937805\n",
            "Epoch: 4, Loss:  0.41337281465530396\n",
            "Epoch: 4, Loss:  0.31730374693870544\n",
            "Epoch: 4, Loss:  0.3134659230709076\n",
            "Epoch: 4, Loss:  0.31757399439811707\n",
            "Epoch: 4, Loss:  0.4131021499633789\n",
            "Epoch: 4, Loss:  0.31339430809020996\n",
            "Epoch: 4, Loss:  0.31336838006973267\n",
            "Epoch: 4, Loss:  0.3136024475097656\n",
            "Epoch: 4, Loss:  0.33092620968818665\n",
            "Epoch: 4, Loss:  0.40380963683128357\n",
            "Epoch: 4, Loss:  0.3467113673686981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-8\"></a>\n",
        "# <span>8. Prédiction des données</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">\n",
        "<p align=\"justify\">Maintenant que les données ont été entrainées, nous pouvons prédire des données de test. Comme prédiction, nous allons dans un premier temps faire des prédictions sur toutes les données de test. Une fois cette prédiction faite, nous pouvons combiner ces prédictions afin de déterminer le type de News. Comme les vraies News ont tendance à être plus longue, si nous avons autant de fake et real News prédiction nous dirons que la News est Vraie. </p>"
      ],
      "metadata": {
        "id": "09BR8pAw6Tv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation():\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    correct_predictions = 0\n",
        "    total_instances = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for count, data in enumerate(testing_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "\n",
        "        # accuracy \n",
        "        classifications = torch.argmax(outputs, dim=1)\n",
        "        labels = torch.argmax(targets, dim=1)\n",
        "        correct_predictions += sum(classifications==labels).item()\n",
        "        total_instances += len(outputs)\n",
        "\n",
        "        # loss \n",
        "        total_loss += ce_loss(outputs, labels)\n",
        "\n",
        "        fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
        "\n",
        "    accuracy = correct_predictions/total_instances\n",
        "    loss = total_loss/total_instances\n",
        "\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"Loss Score = {loss}\")\n",
        "\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "HqGsmQgV7IJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, targets = validation()"
      ],
      "metadata": {
        "id": "qqjHEDooHz4i",
        "outputId": "47feccf3-ba02-4920-8b23-ee2ab4a9bf47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.96\n",
            "Loss Score = 0.03531963378190994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df_test['pred'] = outputs\n",
        "cleaned_df_test.head()"
      ],
      "metadata": {
        "id": "V1A2NZ6deQiu",
        "outputId": "d7d0de7f-ad0a-42ba-f670-0a567328988a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data   label  \\\n",
              "0  président groupe lrem a pris toutes pincettes....  [1, 0]   \n",
              "1  négociateur». patron groupe majoritaire connaî...  [1, 0]   \n",
              "2  titre personnel» souhaite gouvernement «mette ...  [1, 0]   \n",
              "3  tir. «c’est micro-aile gauche fait mousse» pré...  [1, 0]   \n",
              "4  villes françaises qualité l'air meilleure moin...  [1, 0]   \n",
              "\n",
              "                                           pred  \n",
              "0   [0.9999217987060547, 7.823276246199384e-05]  \n",
              "1    [0.9999257326126099, 7.42080228519626e-05]  \n",
              "2   [0.9999220371246338, 7.797416765242815e-05]  \n",
              "3  [0.9998860359191895, 0.00011391906446078792]  \n",
              "4   [0.9999215602874756, 7.837941666366532e-05]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29d57331-13ba-459c-9a26-c2b8eb6148bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>président groupe lrem a pris toutes pincettes....</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0.9999217987060547, 7.823276246199384e-05]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>négociateur». patron groupe majoritaire connaî...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0.9999257326126099, 7.42080228519626e-05]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>titre personnel» souhaite gouvernement «mette ...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0.9999220371246338, 7.797416765242815e-05]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tir. «c’est micro-aile gauche fait mousse» pré...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0.9998860359191895, 0.00011391906446078792]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>villes françaises qualité l'air meilleure moin...</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0.9999215602874756, 7.837941666366532e-05]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29d57331-13ba-459c-9a26-c2b8eb6148bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29d57331-13ba-459c-9a26-c2b8eb6148bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29d57331-13ba-459c-9a26-c2b8eb6148bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 0\n",
        "df_test['pred'] = [list() for x in range(len(df_test.index))]\n",
        "for idx,row in df_test.iterrows():\n",
        "  for i in range(row['len_split']): \n",
        "    row['pred'].append(cleaned_df_test.loc[pos]['pred'])\n",
        "    pos += 1"
      ],
      "metadata": {
        "id": "xMtXCnhErx-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['prediction'] = df_test['pred'].apply(lambda x: [1, 0] if np.argmax(np.sum(x, axis = 0)) == 0 else [0, 1])\n",
        "df_test['label_pred'] = df_test['pred'].apply(lambda x: np.argmax(np.sum(x, axis = 0)))"
      ],
      "metadata": {
        "id": "LAIdo60rp9Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(df_test['label_pred'], df_test['label'])\n",
        "print(f\"Accuracy Score = {accuracy}\")"
      ],
      "metadata": {
        "id": "BfiPQFHNrKqg",
        "outputId": "44246925-d89b-4b15-d64a-3f2e346e1986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.948559670781893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section-9\"></a>\n",
        "# <span>9. Sauvegarde du modèle</span>\n",
        "<hr style=\"border-bottom: solid;background-color:light;color:black;\">"
      ],
      "metadata": {
        "id": "khJH34-Y6eOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'model': BERTClass(),\n",
        "              'state_dict': model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, '/content/drive/MyDrive/HandOnAI_2_NLP/transformer_model.pth')"
      ],
      "metadata": {
        "id": "txBBhkjlIBKj",
        "outputId": "0ff0ca10-7b6c-45e3-b102-622a26d46f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cmarkea/distilcamembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CamembertModel were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    }
  ]
}